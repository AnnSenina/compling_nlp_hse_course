{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Неточности в задании (оценка не снижалась)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задании, где нужно найти ошибки стемминга, когда слова не изменяются после стемминга не очень корректная формулировка - нужны именно ошибки, когда слово не изменилось после стеминга, а должно было! Часто приводились слова, которые стемить не нужно. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во втором задании сказано \"Приведите очищенный текст к нижнему регистру, удалите все знаки пунктуации, разделите на предложения библиотекой rusenttokenize, токенизируйте библиотекой razdel_tokenize. \". Тут есть ошибка в порядке предобработки - разбивать на предложения нужно в самом начале, т.к. без регистра и пунктуации будут получаться плохие предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример с сентенайзером вначале"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Во втором задании сказано \"Приведите очищенный текст к нижнему регистру, удалите все знаки пунктуации, разделите на предложения библиотекой rusenttokenize, токенизируйте библиотекой razdel_tokenize. \". Тут есть ошибка в порядке предобработки - разбивать на предложения нужно в самом начале, т.к. без регистра и пунктуации будут получаться плохие предложения. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Во втором задании сказано \"Приведите очищенный текст к нижнему регистру, удалите все знаки пунктуации, разделите на предложения библиотекой rusenttokenize, токенизируйте библиотекой razdel_tokenize.',\n",
       " '\".',\n",
       " 'Тут есть ошибка в порядке предобработки - разбивать на предложения нужно в самом начале, т.к. без регистра и пунктуации будут получаться плохие предложения.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import sentenize\n",
    "[sent.text for sent in list(sentenize(text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пример с сентенайзером в порядке по заданию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['во втором задании сказано приведите очищенный текст к нижнему регистру удалите все знаки пунктуации разделите на предложения библиотекой rsekeze токенизируйте библиотекой rzdelkeze  тут есть ошибка в порядке предобработки  разбивать на предложения нужно в самом начале тк без регистра и пунктуации будут получаться плохие предложения']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import sentenize\n",
    "from string import punctuation\n",
    "import re\n",
    "text = text.lower()\n",
    "text = re.sub(f'[{punctuation}]', '', text)\n",
    "[sent.text for sent in list(sentenize(text))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек по коду (не влияет на оценку)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Питон удобный язык, но не самый быстрый, поэтому нужно следить за эффективностью кода. Хотя бы на базовом уровне.\n",
    "\n",
    "Вот несколько советов:\n",
    "\n",
    "    Циклы - самый большой источник неэффективности в вашем коде. Используйте минимальное возможное количество циклов.  Старайтесь     никогда не использовать вложенные циклы;\n",
    "    \n",
    "    Изучите базовые структуры данных питона (их слабые и сильные стороны)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Примеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая генерирует рандомное слово из заданного набора символов. Сделаем два списка и попробуем проверить сколько одинаковых слов в этих списках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_letters\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_word(letters, n):\n",
    "    word = ''.join(choice(list(letters), n))\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dfSVh'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_random_word(ascii_letters, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [generate_random_word(ascii_letters, 3) for i in range(10000)]\n",
    "list_2 = [generate_random_word(ascii_letters, 3) for i in range(10000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ПЛОХОЙ ПРИМЕР"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.83 s, sys: 7.43 ms, total: 4.84 s\n",
      "Wall time: 4.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "intersection = []\n",
    "\n",
    "for word1 in list_1:\n",
    "    for word2 in list_2:\n",
    "        if word1 == word2:\n",
    "            intersection.append(word1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получше, но все равно плохо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.2 s, sys: 4.05 ms, total: 1.2 s\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "intersection = []\n",
    "\n",
    "for word1 in list_1:\n",
    "    if word1 in list_2: # Список не подходит для оператора in\n",
    "        intersection.append(word1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получше, но все еще с циклом "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.29 ms, sys: 11 µs, total: 1.3 ms\n",
      "Wall time: 1.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "intersection = []\n",
    "\n",
    "# преобразуем список в множество\n",
    "set_2 = set(list_2)\n",
    "\n",
    "for word1 in list_1:\n",
    "    if word1 in set_2:\n",
    "        intersection.append(word1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Совсем без цикла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.04 ms, sys: 33 µs, total: 1.07 ms\n",
      "Wall time: 1.08 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# между множествами можно посчитать пересечение\n",
    "intersection = set(list_1) & set(list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте для каждого слова найдем его частоту в первом и втором списках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Плохой пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У списка конечно есть метод count, но лучше им не пользоваться (по крайней мере в такой задаче)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.12 s, sys: 9.77 ms, total: 5.13 s\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab2count = {}\n",
    "\n",
    "for word in list_1:\n",
    "    vocab2count[word] = [list_1.count(word), list_2.count(word)]\n",
    "\n",
    "for word in list_2:\n",
    "    vocab2count[word] = [list_1.count(word), list_2.count(word)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Встроенный счетчик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для частотных словарей удобно использовать Counter. Он оптимизирован под сбор частотностей, поэтому лучше всегда пользоваться им, а не писать свое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 86.6 ms, sys: 16.4 ms, total: 103 ms\n",
      "Wall time: 102 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab2count = {}\n",
    "\n",
    "vocab1 = Counter(list_1)\n",
    "vocab2 = Counter(list_2)\n",
    "vocab = set(vocab1.keys()) | set(vocab2.keys())\n",
    "\n",
    "for word in vocab:\n",
    "    vocab2count[word] = [vocab1[word], vocab2[word]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте переопределим второй список - там будут первые символы слов из первого списка. Теперь сделаем маппинг первая буква: все слова, которые с нее начинаются. (Это похоже на задание с поиском ошибок в стемминге)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [generate_random_word(ascii_letters, 3) for i in range(10000)]\n",
    "list_2 = [word[:1] for word in list_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого хорошо подходит defaultdict - словарь с дефолтным значением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.01 ms, sys: 5 µs, total: 2.02 ms\n",
      "Wall time: 2.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mapping = defaultdict(list)\n",
    "\n",
    "for word, letter in zip(list_1, list_2): # zip позволяет итерироваться по двум спискам одновременно\n",
    "    mapping[letter].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.8 ms, sys: 47 µs, total: 2.85 ms\n",
      "Wall time: 2.85 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# чтобы было понятно чем удобнее вот пример без него\n",
    "\n",
    "\n",
    "mapping = {}\n",
    "\n",
    "for word, letter in zip(list_1, list_2):\n",
    "    if letter in mapping:\n",
    "        mapping[letter].append(word)\n",
    "    else:\n",
    "        mapping[letter] = [word]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JNk', 'Jac', 'JZN', 'JyW', 'JPP', 'JIq', 'JlL', 'JGy', 'JtJ', 'Jev']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping['J'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lambda, map, filter не улучшают эффективность, но сильно снижают читаемость\n",
    "\n",
    "Старайтесь не пользоваться lambda, map, filter вообще "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим нам надо выбрать слова из словаря, встречающиеся больше 2 раз и привезти их к нижнему регистру. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Плохой пример с lambda map filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.06 ms, sys: 9 µs, total: 3.07 ms\n",
      "Wall time: 3.07 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lower_frequent = list(map(lambda x: x[0].lower(), filter(lambda x: x[1] > 2, vocab1.most_common())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['auk', 'tbw', 'ndc', 'tzl', 'fjs', 'sco']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeating_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лучше вот так написать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По времени тут нет различия, но такой вариант намного более читаемый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.4 ms, sys: 15 µs, total: 2.42 ms\n",
      "Wall time: 2.42 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['auk', 'tbw', 'ndc', 'tzl', 'fjs', 'sco']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "[word.lower() for word, count in vocab1.most_common() if count > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Не вызывайте два раза то, что можно сохранить в переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# код не запускается, но должно быть читаемо\n",
    "lemmas = list()\n",
    "\n",
    "for sentence in sentences:\n",
    "    for token in sentence:\n",
    "        if mystem.lemmatize(token)[0] != morph.parse(token)[0].normal_form:\n",
    "            lemmas.append((token, morph.parse(token)[0].normal_form, mystem.lemmatize(token)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот тут лемматизация сначала вызывается для сравнения, а потом для добавления в список. Можно сохранить в переменную и переиспользовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# код не запускается, но должно быть читаемо\n",
    "lemmas = list()\n",
    "\n",
    "for sentence in sentences:\n",
    "    for token in sentence:\n",
    "        lemma_pymorphy = morph.parse(token)[0].normal_form\n",
    "        lemma_mystem = mystem.lemmatize(token)[0]\n",
    "        if lemma_pymorphy != lemma_mystem:\n",
    "            lemmas.append((token, lemma_mystem, lemma_pymorphy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще есть моржовый оператор, пример тут - https://habr.com/ru/company/otus/blog/472432/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
