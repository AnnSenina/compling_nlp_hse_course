{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 1. Предобработка текстовых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале любой работы с текстом, как правило, требуется выполнить одни и теже действия: удалить все лишнее, разбить на предложения, токенизировать, нормализовать. На этом занятии мы разберем каждый из этих этапов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы открыли тетрадку в Colab, нужно установить майстем и майморфи.  \n",
    "Версия майстема указана, так как в Colab может быть ошибка с новой версией. Если вы работает не в колабе, то можно убрать ее и использовать последнюю. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymystem3==0.1.10 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (0.1.10)\n",
      "Requirement already satisfied: requests in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from pymystem3==0.1.10) (2.22.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests->pymystem3==0.1.10) (2.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests->pymystem3==0.1.10) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests->pymystem3==0.1.10) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests->pymystem3==0.1.10) (1.23)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/mnefedov/.pyenv/versions/3.6.5/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pymorphy2[fast] in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (0.8)\n",
      "Requirement already satisfied: docopt>=0.6 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from pymorphy2[fast]) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from pymorphy2[fast]) (2.4.393442.3710985)\n",
      "Requirement already satisfied: dawg-python>=0.7 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from pymorphy2[fast]) (0.7.2)\n",
      "Requirement already satisfied: DAWG>=0.7.3; extra == \"fast\" in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from pymorphy2[fast]) (0.7.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/mnefedov/.pyenv/versions/3.6.5/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: razdel in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (0.5.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/mnefedov/.pyenv/versions/3.6.5/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: gensim in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (3.4.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: boto>=2.32 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto3 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim) (1.11.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (2.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (1.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests->smart-open>=1.2.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from boto3->smart-open>=1.2.1->gensim) (1.14.9)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.2)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.9->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.9->boto3->smart-open>=1.2.1->gensim) (2.7.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/mnefedov/.pyenv/versions/3.6.5/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: nltk in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (3.2.5)\n",
      "Requirement already satisfied: six in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from nltk) (1.11.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/mnefedov/.pyenv/versions/3.6.5/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: rusenttokenize in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (0.0.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/mnefedov/.pyenv/versions/3.6.5/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting regex\n",
      "  Downloading regex-2020.10.23.tar.gz (690 kB)\n",
      "\u001b[K     |████████████████████████████████| 690 kB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: regex\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for regex: filename=regex-2020.10.23-cp36-cp36m-macosx_10_15_x86_64.whl size=282741 sha256=ec6d98c5c984073c795e9d74563b2c8c22045b0f140b79d8b19b34f289c0ad28\n",
      "  Stored in directory: /Users/mnefedov/Library/Caches/pip/wheels/15/36/9c/9328400fae53fd0bd7ba7e6f758720fb08e45f2936e1b567ca\n",
      "Successfully built regex\n",
      "Installing collected packages: regex\n",
      "Successfully installed regex-2020.10.23\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/mnefedov/.pyenv/versions/3.6.5/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3==0.1.10\n",
    "!pip install pymorphy2[fast]\n",
    "!pip install razdel\n",
    "!pip install gensim\n",
    "!pip install nltk\n",
    "!pip install rusenttokenize\n",
    "!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pymorphy2[fast] - быстрая версия пайморфи. Если у вас windows, то он вряд ли установится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сразу импортируем все нужные библиотеки\n",
    "# подробнее о каждой из них я расскажу по ходу \n",
    "import string\n",
    "from gensim.utils import tokenize\n",
    "from gensim.summarization.textcleaner import split_sentences\n",
    "from rusenttokenize import ru_sent_tokenize\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re, os, json\n",
    "mystem = Mystem()\n",
    "morph = MorphAnalyzer()\n",
    "# если есть ошибки, доустановите библиотеки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление лишнего"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто в данных, с которыми нам нужно работать помимо текста присутствует ещё какая-то лишняя информация: тэги, ссылки, код, разметка. Она, конечно, не всегда лишняя, но обычно от неё лучше избавиться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем в качестве примера статью с Хабрахабра. Она скачана автоматически и в там остались некоторые тэги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — <a href=\"http://www.crazyegg.com\" title=\"Сумасшедшие яйца\">CrazyEgg</a>. Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо. Запоминается? Отлично!<br><br><img src=\"http://img172.imageshack.us/img172/8434/18274658kc4.png\" alt=\"Сумасшедшее яйцо\"><br><br><blockquote><h3>Что это такое?</h3><br>\n",
    "Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов.<br>\n",
    "Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые).<br><br><img src=\"https://habrastorage.org/getpro/habr/post_images/7c7/298/33c/7c729833cd942cc493e68833e3e0f12d.jpg\" alt=\"Тепловое отслеживание популярности\"><br></blockquote><br><br><a name=\"habracut\"></a><br><br><blockquote><h3>Для кого это?</h3><br>\n",
    "Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад. Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную. Дабы написать этот обзор я не поленился заплатить 19 долларов (в месяц) выбрав средний вариант — для нескольких проектов с включенными дополнительными функциями.<br><br><img src=\"https://habrastorage.org/getpro/habr/post_images/0b0/0a0/b16/0b00a0b16b1eda28e35f39487dcd2545.jpg\" alt=\"Отслеживание ссылок\"></blockquote><br><blockquote><img src=\"https://habrastorage.org/getpro/habr/post_images/0b5/433/892/0b54338921665ffb5a90930147296f5b.jpg\" alt=\"Список по популярности\"><br><br>\n",
    "Да-да, сервис не бесплатен. Точнее бесплатная возможность потестировать есть, но она немного обрезана (можно отслеживать только 5000 посетителей и всего 4 страницы на сайте (внимание — 4 страницы, а не сайтов), т.е. вполне хватает для того, чтобы понять полезность сервиса).</blockquote><br><blockquote><h3>Зачем это?</h3><br>\n",
    "С помощью этого сервиса можно тасовать блоки на сайте, которые полезны пользователям больше всего. Больше не нужно спорить создателям — какой блок где расположить. В этом им поможет <a href=\"http://ttp://www.crazyegg.com\" title=\"Сумасшедшие яйца\">Сумасшедшее яйцо</a>.<br><br><img src=\"https://habrastorage.org/getpro/habr/post_images/38c/af8/e75/38caf8e753782a01dc6419d3902edd57.jpg\" alt=\"Добавление проекта\"></blockquote><br><blockquote>Также этот сервис поможет вам понять — в какой зоне сайта лучше всего располагать рекламу, когда в вашем сервисе речь зайдет о монетизации. Ведь альтруизм это хорошо, а деньги на содержание сервиса нужны, и не лишним будет вычислить зоны где реклама будет приносить наибольшую отдачу, и наименьшее раздражение у пользователей.<br><br><img src=\"https://habrastorage.org/getpro/habr/post_images/0dd/3fb/b34/0dd3fbb34709e77f3fbcd6523c7eac77.jpg\" alt=\"еще полезности\"></blockquote><br><blockquote><h3>Как это работает?</h3><br>\n",
    "Никаких километровых скриптов вставлять не нужно, достаточно вставиь 2 строчки яваскрипта, и сервис начнет отслеживание. Насколько я понял — исполнительный скрипт работает на сервере <a href=\"http://www.crazyegg.com\" title=\"Сумасшедшие яйца\">CrazyEgg</a>, поэтому ваш сайт от этого в производительности не потеряет ни секунды, а полезность довольно таки большая.<br><br><img src=\"https://habrastorage.org/getpro/habr/post_images/a90/e4e/e67/a90e4ee6760978463e6306a2f5982e24.jpg\" alt=\"управление популярностью\"></blockquote><br><blockquote><h3>Сколько это стоит?</h3><br>\n",
    "Как я уже упоминал — сервис далеко не бесплатен, хоть и имеет тестовую-бесплатную версию. Расскажу подробнее о тарификации.</blockquote><br><blockquote>1. Бесплатная тестовая версия. Включает в себя возможность отслеживания 5 000 посещений, 4 страницы на сайте.<br><br>\n",
    "2. Базовая версия. В этой версии можно отследить 10 000 посещений, и 10 страниц, что вполне достаточно для среднего корпоративного сайта. Стоит базовый комплект — 9 долларов в месяц. В этот комплект включены все дополнительные функции.<br><br>\n",
    "3. Версия «Стандарт». В неё входит возможность отслеживания 25 000 посещений на 20 страницах. Вполне подходит для тестирования нового стартапа. Стоит она 19 долларов в месяц, именно её я купил для тестирования сервиса, и написания этого обзора.<br><br>\n",
    "4. Версия «Плюс». Отличается от предыдущей возможностью отслеживания 100 000 посещений, 50 страниц. Очень хороший тариф для крупных сервисов. Стоит 49 долларов в месяц. Довольно большие деньги за сервис, но они обычно с лихвой окупаются.<br><br>\n",
    "5. Версия «Про». Стоит почти 100 долларов, имеет возможность отследить 250 000 посещений на ста страницах. Тариф подходит для монстров с большой посещаемостью и большим количеством страниц.<br><br><img src=\"https://habrastorage.org/getpro/habr/post_images/f73/fb2/62d/f73fb262da4618a8dde67690cfd191ea.jpg\" alt=\"Отслеживание статистики\"></blockquote><br><blockquote><h3>Есть и аналоги</h3><br>\n",
    "Я не поленился, и собрал еще пару ссылок с аналогами, которые предлагают такие же услуги, но немного дешевле.</blockquote><br><blockquote> 1. <a href=\"https://www.google.com/analytics/home/?hl=en\" title=\"Шикарный сбор и анализ статистики\">Google Analytics</a> — бесплатный сервис для сбора и анализа статистики, вывод статистики в наиболее наглядной форме, и без разнообразных рейтингов, счетчиков. Очень подробная и полезная вещь. Рекомендую, т.к. сам пользуюсь им для этого блога.<br><br>\n",
    "2. <a href=\"http://www.mapsurface.com/\" title=\"Сервис для отслеживания популярности блоков на сайте\">MapSurface</a> — сам еще не использовал (т.к. предпочел CrazyEgg), но врядли будучи плохим сервис собрал бы множество положительных отзывов. К сожалению он сейчас находится в статусе закрытой беты.</blockquote><br><blockquote><h3>Вывод</h3><br>\n",
    "Использовать можно, и нужно. Вот только тарифы довольно больно кусаются, но обычно эти деньги потом с лихвой отбиваются на повышении конвертации посетителей в деньги. Использовать сервис нужно для тестирования рекламных мест и удобства отдельных страниц, что помогает опять же повысить конвертацию. В общем и целом — <a href=\"http://ttp://www.crazyegg.com\">полезная вещь</a> для каждого владельца сайтов, а для юзабилиста вообще практически обязательна. К счастью для людей, которые поиздержались деньгами в этом месяце — есть полезные аналоги.<br><br><img src=\"http://img241.imageshack.us/img241/2346/confettitnml5.jpg\" alt=\"Интересная идея визуализации популярности - конфети\"></blockquote><br><br>\n",
    "Автор: <a href=\"http://www.birzool.com/\" title=\"Я пишу о юзабилити веб интерфейсов\">Ярослав Бирзул</a> (DezmASter).<br>\n",
    "Источник: <a href=\"http://www.birzool.com/crazyegg/\" title=\"Сумасшедшие яйца, первоисточник\">Блог о юзабилити веб интерфейсов</a>.<br><br>\n",
    "PS: Всех с прошедшим Новым годом! От всей души желаю вам всего самого-самого лучшего, чего вы желаете только в самых сокровенных мечтах. Удачно вам провести время.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В html все тэги заключаются в фигурные скобки. Мы можем испьзовать это, чтобы легко избавиться от всех тэгов сразу. Напишем регулярное выражение, которое будет захватывать всё, что попадает между символами < и >, и не является '>'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re - модуль регулярных выражений в питоне\n",
    "# функция sub заменяет все, что подходит под шаблон, на указанный текст\n",
    "def remove_tags_1(text):\n",
    "    return re.sub(r'<[^>]+>', '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим как работает наша функция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg. Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо. Запоминается? Отлично!Что это такое?\n",
      "Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов.\n",
      "Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые).Для кого это?\n",
      "Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад. Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную. Дабы написать этот обзор я не поленился заплатить 19 долларов (в месяц) выбрав средний вариант — для нескольких проектов с включенными дополнительными функциями.\n",
      "Да-да, сервис не бесплатен. Точнее бесплатная возможность потестировать есть, но она немного обрезана (можно отслеживать только 5000 посетителей и всего 4 страницы на сайте (внимание — 4 страницы, а не сайтов), т.е. вполне хватает для того, чтобы понять полезность сервиса).Зачем это?\n",
      "С помощью этого сервиса можно тасовать блоки на сайте, которые полезны пользователям больше всего. Больше не нужно спорить создателям — какой блок где расположить. В этом им поможет Сумасшедшее яйцо.Также этот сервис поможет вам понять — в какой зоне сайта лучше всего располагать рекламу, когда в вашем сервисе речь зайдет о монетизации. Ведь альтруизм это хорошо, а деньги на содержание сервиса нужны, и не лишним будет вычислить зоны где реклама будет приносить наибольшую отдачу, и наименьшее раздражение у пользователей.Как это работает?\n",
      "Никаких километровых скриптов вставлять не нужно, достаточно вставиь 2 строчки яваскрипта, и сервис начнет отслеживание. Насколько я понял — исполнительный скрипт работает на сервере CrazyEgg, поэтому ваш сайт от этого в производительности не потеряет ни секунды, а полезность довольно таки большая.Сколько это стоит?\n",
      "Как я уже упоминал — сервис далеко не бесплатен, хоть и имеет тестовую-бесплатную версию. Расскажу подробнее о тарификации.1. Бесплатная тестовая версия. Включает в себя возможность отслеживания 5 000 посещений, 4 страницы на сайте.\n",
      "2. Базовая версия. В этой версии можно отследить 10 000 посещений, и 10 страниц, что вполне достаточно для среднего корпоративного сайта. Стоит базовый комплект — 9 долларов в месяц. В этот комплект включены все дополнительные функции.\n",
      "3. Версия «Стандарт». В неё входит возможность отслеживания 25 000 посещений на 20 страницах. Вполне подходит для тестирования нового стартапа. Стоит она 19 долларов в месяц, именно её я купил для тестирования сервиса, и написания этого обзора.\n",
      "4. Версия «Плюс». Отличается от предыдущей возможностью отслеживания 100 000 посещений, 50 страниц. Очень хороший тариф для крупных сервисов. Стоит 49 долларов в месяц. Довольно большие деньги за сервис, но они обычно с лихвой окупаются.\n",
      "5. Версия «Про». Стоит почти 100 долларов, имеет возможность отследить 250 000 посещений на ста страницах. Тариф подходит для монстров с большой посещаемостью и большим количеством страниц.Есть и аналоги\n",
      "Я не поленился, и собрал еще пару ссылок с аналогами, которые предлагают такие же услуги, но немного дешевле. 1. Google Analytics — бесплатный сервис для сбора и анализа статистики, вывод статистики в наиболее наглядной форме, и без разнообразных рейтингов, счетчиков. Очень подробная и полезная вещь. Рекомендую, т.к. сам пользуюсь им для этого блога.\n",
      "2. MapSurface — сам еще не использовал (т.к. предпочел CrazyEgg), но врядли будучи плохим сервис собрал бы множество положительных отзывов. К сожалению он сейчас находится в статусе закрытой беты.Вывод\n",
      "Использовать можно, и нужно. Вот только тарифы довольно больно кусаются, но обычно эти деньги потом с лихвой отбиваются на повышении конвертации посетителей в деньги. Использовать сервис нужно для тестирования рекламных мест и удобства отдельных страниц, что помогает опять же повысить конвертацию. В общем и целом — полезная вещь для каждого владельца сайтов, а для юзабилиста вообще практически обязательна. К счастью для людей, которые поиздержались деньгами в этом месяце — есть полезные аналоги.\n",
      "Автор: Ярослав Бирзул (DezmASter).\n",
      "Источник: Блог о юзабилити веб интерфейсов.\n",
      "PS: Всех с прошедшим Новым годом! От всей души желаю вам всего самого-самого лучшего, чего вы желаете только в самых сокровенных мечтах. Удачно вам провести время.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(remove_tags_1(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что в некоторых местах удаление тэгов приводит к тому, что между точкой и началом следующего \n",
    "предложения нет пробела, а это может помешать правильно токенизировать текст,\n",
    "поэтому сделаем так, чтобы тэг заменялся пробелом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags_2(text):\n",
    "    return re.sub(r'<[^>]+>', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сегодняшняя заметка будет о сервисе отслеживания активности пользователя —  CrazyEgg . Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо. Запоминается? Отлично!       Что это такое?  \n",
      "Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов. \n",
      "Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые).             Для кого это?  \n",
      "Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад. Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную. Дабы написать этот обзор я не поленился заплатить 19 долларов (в месяц) выбрав средний вариант — для нескольких проектов с включенными дополнительными функциями.         \n",
      "Да-да, сервис не бесплатен. Точнее бесплатная возможность потестировать есть, но она немного обрезана (можно отслеживать только 5000 посетителей и всего 4 страницы на сайте (внимание — 4 страницы, а не сайтов), т.е. вполне хватает для того, чтобы понять полезность сервиса).    Зачем это?  \n",
      "С помощью этого сервиса можно тасовать блоки на сайте, которые полезны пользователям больше всего. Больше не нужно спорить создателям — какой блок где расположить. В этом им поможет  Сумасшедшее яйцо .      Также этот сервис поможет вам понять — в какой зоне сайта лучше всего располагать рекламу, когда в вашем сервисе речь зайдет о монетизации. Ведь альтруизм это хорошо, а деньги на содержание сервиса нужны, и не лишним будет вычислить зоны где реклама будет приносить наибольшую отдачу, и наименьшее раздражение у пользователей.       Как это работает?  \n",
      "Никаких километровых скриптов вставлять не нужно, достаточно вставиь 2 строчки яваскрипта, и сервис начнет отслеживание. Насколько я понял — исполнительный скрипт работает на сервере  CrazyEgg , поэтому ваш сайт от этого в производительности не потеряет ни секунды, а полезность довольно таки большая.       Сколько это стоит?  \n",
      "Как я уже упоминал — сервис далеко не бесплатен, хоть и имеет тестовую-бесплатную версию. Расскажу подробнее о тарификации.   1. Бесплатная тестовая версия. Включает в себя возможность отслеживания 5 000 посещений, 4 страницы на сайте.  \n",
      "2. Базовая версия. В этой версии можно отследить 10 000 посещений, и 10 страниц, что вполне достаточно для среднего корпоративного сайта. Стоит базовый комплект — 9 долларов в месяц. В этот комплект включены все дополнительные функции.  \n",
      "3. Версия «Стандарт». В неё входит возможность отслеживания 25 000 посещений на 20 страницах. Вполне подходит для тестирования нового стартапа. Стоит она 19 долларов в месяц, именно её я купил для тестирования сервиса, и написания этого обзора.  \n",
      "4. Версия «Плюс». Отличается от предыдущей возможностью отслеживания 100 000 посещений, 50 страниц. Очень хороший тариф для крупных сервисов. Стоит 49 долларов в месяц. Довольно большие деньги за сервис, но они обычно с лихвой окупаются.  \n",
      "5. Версия «Про». Стоит почти 100 долларов, имеет возможность отследить 250 000 посещений на ста страницах. Тариф подходит для монстров с большой посещаемостью и большим количеством страниц.       Есть и аналоги  \n",
      "Я не поленился, и собрал еще пару ссылок с аналогами, которые предлагают такие же услуги, но немного дешевле.    1.  Google Analytics  — бесплатный сервис для сбора и анализа статистики, вывод статистики в наиболее наглядной форме, и без разнообразных рейтингов, счетчиков. Очень подробная и полезная вещь. Рекомендую, т.к. сам пользуюсь им для этого блога.  \n",
      "2.  MapSurface  — сам еще не использовал (т.к. предпочел CrazyEgg), но врядли будучи плохим сервис собрал бы множество положительных отзывов. К сожалению он сейчас находится в статусе закрытой беты.    Вывод  \n",
      "Использовать можно, и нужно. Вот только тарифы довольно больно кусаются, но обычно эти деньги потом с лихвой отбиваются на повышении конвертации посетителей в деньги. Использовать сервис нужно для тестирования рекламных мест и удобства отдельных страниц, что помогает опять же повысить конвертацию. В общем и целом —  полезная вещь  для каждого владельца сайтов, а для юзабилиста вообще практически обязательна. К счастью для людей, которые поиздержались деньгами в этом месяце — есть полезные аналоги.      \n",
      "Автор:  Ярослав Бирзул  (DezmASter). \n",
      "Источник:  Блог о юзабилити веб интерфейсов .  \n",
      "PS: Всех с прошедшим Новым годом! От всей души желаю вам всего самого-самого лучшего, чего вы желаете только в самых сокровенных мечтах. Удачно вам провести время.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(remove_tags_2(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь куски текста не слепаются, но появились последовательности из нескольких пробелов, чтобы убрать их добавим ещё одно регулярное выражение и применим его к тексту, из которого уже удалили тэги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags_3(text):\n",
    "    no_tags_text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    no_space_sequences_text = re.sub('  +', ' ', no_tags_text)\n",
    "    return no_space_sequences_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg . Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо. Запоминается? Отлично! Что это такое? \n",
      "Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов. \n",
      "Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые). Для кого это? \n",
      "Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад. Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную. Дабы написать этот обзор я не поленился заплатить 19 долларов (в месяц) выбрав средний вариант — для нескольких проектов с включенными дополнительными функциями. \n",
      "Да-да, сервис не бесплатен. Точнее бесплатная возможность потестировать есть, но она немного обрезана (можно отслеживать только 5000 посетителей и всего 4 страницы на сайте (внимание — 4 страницы, а не сайтов), т.е. вполне хватает для того, чтобы понять полезность сервиса). Зачем это? \n",
      "С помощью этого сервиса можно тасовать блоки на сайте, которые полезны пользователям больше всего. Больше не нужно спорить создателям — какой блок где расположить. В этом им поможет Сумасшедшее яйцо . Также этот сервис поможет вам понять — в какой зоне сайта лучше всего располагать рекламу, когда в вашем сервисе речь зайдет о монетизации. Ведь альтруизм это хорошо, а деньги на содержание сервиса нужны, и не лишним будет вычислить зоны где реклама будет приносить наибольшую отдачу, и наименьшее раздражение у пользователей. Как это работает? \n",
      "Никаких километровых скриптов вставлять не нужно, достаточно вставиь 2 строчки яваскрипта, и сервис начнет отслеживание. Насколько я понял — исполнительный скрипт работает на сервере CrazyEgg , поэтому ваш сайт от этого в производительности не потеряет ни секунды, а полезность довольно таки большая. Сколько это стоит? \n",
      "Как я уже упоминал — сервис далеко не бесплатен, хоть и имеет тестовую-бесплатную версию. Расскажу подробнее о тарификации. 1. Бесплатная тестовая версия. Включает в себя возможность отслеживания 5 000 посещений, 4 страницы на сайте. \n",
      "2. Базовая версия. В этой версии можно отследить 10 000 посещений, и 10 страниц, что вполне достаточно для среднего корпоративного сайта. Стоит базовый комплект — 9 долларов в месяц. В этот комплект включены все дополнительные функции. \n",
      "3. Версия «Стандарт». В неё входит возможность отслеживания 25 000 посещений на 20 страницах. Вполне подходит для тестирования нового стартапа. Стоит она 19 долларов в месяц, именно её я купил для тестирования сервиса, и написания этого обзора. \n",
      "4. Версия «Плюс». Отличается от предыдущей возможностью отслеживания 100 000 посещений, 50 страниц. Очень хороший тариф для крупных сервисов. Стоит 49 долларов в месяц. Довольно большие деньги за сервис, но они обычно с лихвой окупаются. \n",
      "5. Версия «Про». Стоит почти 100 долларов, имеет возможность отследить 250 000 посещений на ста страницах. Тариф подходит для монстров с большой посещаемостью и большим количеством страниц. Есть и аналоги \n",
      "Я не поленился, и собрал еще пару ссылок с аналогами, которые предлагают такие же услуги, но немного дешевле. 1. Google Analytics — бесплатный сервис для сбора и анализа статистики, вывод статистики в наиболее наглядной форме, и без разнообразных рейтингов, счетчиков. Очень подробная и полезная вещь. Рекомендую, т.к. сам пользуюсь им для этого блога. \n",
      "2. MapSurface — сам еще не использовал (т.к. предпочел CrazyEgg), но врядли будучи плохим сервис собрал бы множество положительных отзывов. К сожалению он сейчас находится в статусе закрытой беты. Вывод \n",
      "Использовать можно, и нужно. Вот только тарифы довольно больно кусаются, но обычно эти деньги потом с лихвой отбиваются на повышении конвертации посетителей в деньги. Использовать сервис нужно для тестирования рекламных мест и удобства отдельных страниц, что помогает опять же повысить конвертацию. В общем и целом — полезная вещь для каждого владельца сайтов, а для юзабилиста вообще практически обязательна. К счастью для людей, которые поиздержались деньгами в этом месяце — есть полезные аналоги. \n",
      "Автор: Ярослав Бирзул (DezmASter). \n",
      "Источник: Блог о юзабилити веб интерфейсов . \n",
      "PS: Всех с прошедшим Новым годом! От всей души желаю вам всего самого-самого лучшего, чего вы желаете только в самых сокровенных мечтах. Удачно вам провести время.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(remove_tags_3(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь текст более менее чистый."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = remove_tags_3(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Говоря о регуляках, стоит еще упомянуть библиотеку - [regex](https://pypi.org/project/regex/) Это можно сказать re 2.0 - тут есть все, что есть в re, но есть и много дополнительных штук. Вот несколько полезных фичей regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['конфети', 'конфети']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex.findall('(конфетти){e<=1}', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['пользователя',\n",
       " 'перемещения',\n",
       " 'пользователей',\n",
       " 'по',\n",
       " 'популярные',\n",
       " 'подобная,',\n",
       " 'позволяет',\n",
       " 'пользователей,',\n",
       " 'простой',\n",
       " 'по',\n",
       " 'популярности\"><br></blockquote><br><br><a',\n",
       " 'планировался',\n",
       " 'первый',\n",
       " 'помощник',\n",
       " 'пользоваться',\n",
       " 'популяризировался',\n",
       " 'пол',\n",
       " 'предполагает',\n",
       " 'платных',\n",
       " 'поленился',\n",
       " 'проектов',\n",
       " 'по',\n",
       " 'популярности\"><br><br>',\n",
       " 'потестировать',\n",
       " 'посетителей',\n",
       " 'понять',\n",
       " 'полезность',\n",
       " 'помощью',\n",
       " 'полезны',\n",
       " 'пользователям',\n",
       " 'поможет',\n",
       " 'проекта\"></blockquote><br><blockquote>Также',\n",
       " 'поможет',\n",
       " 'понять',\n",
       " 'приносить',\n",
       " 'пользователей.<br><br><img',\n",
       " 'полезности\"></blockquote><br><blockquote><h3>Как',\n",
       " 'понял',\n",
       " 'поэтому',\n",
       " 'производительности',\n",
       " 'потеряет',\n",
       " 'полезность',\n",
       " 'популярностью\"></blockquote><br><blockquote><h3>Сколько',\n",
       " 'подробнее',\n",
       " 'посещений,',\n",
       " 'посещений,',\n",
       " 'посещений',\n",
       " 'подходит',\n",
       " 'предыдущей',\n",
       " 'посещений,',\n",
       " 'почти',\n",
       " 'посещений',\n",
       " 'подходит',\n",
       " 'посещаемостью',\n",
       " 'поленился,',\n",
       " 'пару',\n",
       " 'предлагают',\n",
       " 'подробная',\n",
       " 'полезная',\n",
       " 'пользуюсь',\n",
       " 'популярности',\n",
       " 'предпочел',\n",
       " 'плохим',\n",
       " 'положительных',\n",
       " 'потом',\n",
       " 'повышении',\n",
       " 'посетителей',\n",
       " 'помогает',\n",
       " 'повысить',\n",
       " 'практически',\n",
       " 'поиздержались',\n",
       " 'полезные',\n",
       " 'популярности',\n",
       " 'пишу',\n",
       " 'первоисточник\">Блог',\n",
       " 'прошедшим',\n",
       " 'провести']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in text.split() if regex.match('п(лат){d<=3,i<=3}', word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['тестовая', 'тестирования', 'тестирования', 'тестирования']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in text.split() if regex.fullmatch('т(ест){i<=10}', word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сплиттер генератор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = regex.splititer(' +', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'сервисе'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# варианты списком"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"александр|алекс|виктор|\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_set = [\"нет\", \"не\", \"он\", 'она']\n",
    "p = regex.compile(r\"\\L<options>\", options=option_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['не', 'не', 'он', 'не', 'она', 'не', 'он', 'не', 'не', 'не']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.findall(text)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистка текста достаточно индивидуальна и каждый раз приходится писать какие-то новые правила. А вот разбиение на предложения, токенизация и лемматизация - на 90% универсальны, т.е. одни и теже решения будут работать во всех задачах. К тому же, есть уже хорошие готовые инструменты для всего этого. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение на предложения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В __nltk__ есть уже готовая функция для разбивки на предложения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nСегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg .',\n",
       " 'Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо.',\n",
       " 'Запоминается?',\n",
       " 'Отлично!',\n",
       " 'Что это такое?',\n",
       " 'Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов.',\n",
       " 'Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые).',\n",
       " 'Для кого это?',\n",
       " 'Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад.',\n",
       " 'Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text, 'russian')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"см. Пункт 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nltk также позволяет обучить свой токенизатор предложений под определенный корпус. Это делается не очень просто, но вот тут есть исчерпывающий туториал - https://nlpforhackers.io/splitting-text-into-sentences/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В __gensim__ тоже есть готовая функция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg .',\n",
       " 'Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо.',\n",
       " 'Запоминается?',\n",
       " 'Отлично!',\n",
       " 'Что это такое?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# это ещё и генератор, т.е. сразу подходит для больших корпусов\n",
    "list(split_sentences(text))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У DeepPavlov есть библиотека [**rusenttokenizer**](https://github.com/deepmipt/ru_sentence_tokenizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Something went wrong while tokenizing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg .',\n",
       " 'Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо.',\n",
       " 'Запоминается?',\n",
       " 'Отлично!',\n",
       " 'Что это такое?',\n",
       " 'Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов.',\n",
       " 'Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые).',\n",
       " 'Для кого это?',\n",
       " 'Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад.',\n",
       " 'Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_sent_tokenize(text)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В проекте Natasha есть библиотека [**razdel**](https://github.com/natasha/razdel). Она чуть более навороченная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = list(sentenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(1,\n",
       "           86,\n",
       "           'Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg .'),\n",
       " Substring(87,\n",
       "           166,\n",
       "           'Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо.'),\n",
       " Substring(167, 180, 'Запоминается?'),\n",
       " Substring(181, 189, 'Отлично!'),\n",
       " Substring(190, 204, 'Что это такое?'),\n",
       " Substring(206,\n",
       "           399,\n",
       "           'Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов.'),\n",
       " Substring(401,\n",
       "           815,\n",
       "           'Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые).'),\n",
       " Substring(816, 829, 'Для кого это?'),\n",
       " Substring(831,\n",
       "           1076,\n",
       "           'Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад.'),\n",
       " Substring(1077,\n",
       "           1189,\n",
       "           'Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную.')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# числа тут - это спаны, индексы начала и конца предложения в изначальном тексте\n",
    "sents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg .',\n",
       " 'Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо.',\n",
       " 'Запоминается?',\n",
       " 'Отлично!',\n",
       " 'Что это такое?',\n",
       " 'Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов.',\n",
       " 'Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые).',\n",
       " 'Для кого это?',\n",
       " 'Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад.',\n",
       " 'Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# у объекта Substring есть атрибуты start, stop и text. С помощью них можно вытащить нужное\n",
    "[sent.text for sent in sents[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если все-таки нужно добавить каких-то специфичных правил разбиения на предложения, можно опять же восползоваться регулярными выражениями. Однако в этом случае регулярка будет посложнее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для разбиения текста по какому-то определенному разделителю подходит функция re.split. Давайте посмотрим, что получится, если в качестве разделителя использовать !?. пробел и заглавную букву.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nСегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg ',\n",
       " ' не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо',\n",
       " 'апоминается',\n",
       " 'тлично',\n",
       " 'то это такое? \\nКак уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов. \\nСервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые)',\n",
       " 'ля кого это? \\nРазумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад',\n",
       " 'тносительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную',\n",
       " 'абы написать этот обзор я не поленился заплатить 19 долларов (в месяц) выбрав средний вариант — для нескольких проектов с включенными дополнительными функциями. \\nДа-да, сервис не бесплатен',\n",
       " 'очнее бесплатная возможность потестировать есть, но она немного обрезана (можно отслеживать только 5000 посетителей и всего 4 страницы на сайте (внимание — 4 страницы, а не сайтов), т.е. вполне хватает для того, чтобы понять полезность сервиса)',\n",
       " 'ачем это? \\nС помощью этого сервиса можно тасовать блоки на сайте, которые полезны пользователям больше всего']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('[!?\\.] [А-Я]', text)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема в том, что сам разделитель удаляется тоже, а нам нужно удалить только пробел между знаками препинания и заглавной буквой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решается эта проблема с помощью __look ahead__ и __look behind__ (название функционала в регулярных выражениях).  \n",
    "Синтаксис там такой:  \n",
    "**(?<=pattern)** положительное look-behind условие  \n",
    "**(?<!pattern)** отрицательное look-behind условие  \n",
    "**(?=pattern)** положительное look-ahead условие  \n",
    "**(?!pattern)** отрицательное look-ahead условие  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробно про это написано тут: https://www.regular-expressions.info/lookaround.html  \n",
    "А совсем подробно про (?...) выражения вообще вот тут - https://www.rexegg.com/regex-disambiguation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look behind и look ahead превращают паттерн в условный, то есть проверяется есть ли он (до или после, соответственно), но его захвата не происходит. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обернём наше регулярное выражение и посмотрим, что получается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg .',\n",
       " 'Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо.',\n",
       " 'Запоминается?',\n",
       " 'Отлично!',\n",
       " 'Что это такое?',\n",
       " 'Как уже сказано выше это сервис для отслеживания перемещения пользователей по сайту — кто куда кликнул, какие ссылки наиболее популярные и тому подобная, разнородная информация для юзабилистов.',\n",
       " 'Сервис позволяет отслеживать активность определенных пользователей, и выводить эти данные в различных формах: «инфракрасная» — где чем активнее область, тем она «теплее», салюты (чем активнее область, тем больше конфети), простой список с сортировкой по активности, колбы (чем заполненнее колба, тем активнее область), облака (на мой взгляд наиболее удобный вариант — совмещает в себе все остальные вместе взятые).',\n",
       " 'Для кого это?',\n",
       " 'Разумеется сервис изначально планировался как первый помощник для юзабилистов, но пользоваться им может каждый, у кого есть деньги — интуитивный интерфейс, и хороший дизайн дает о себе знать — сервис массово популяризировался пол года-год назад.',\n",
       " 'Относительно недорогой, но уж точно не из дешевых — сервис предполагает собой 4 платных линии и одну бесплатную.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('(?<=[\\.?!]) +(?=[А-ЯЁ])', text.replace('\\n', ' '))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы разбили текст на предложения. Теперь предложения нужно разбить на токены. Под токенами обычно понимаются слова, но это могут быть и какие-то более длинные или короткие куски. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ токенизации -- стандартный питоновский __str.split__ метод.\n",
    "    По умолчанию он разбивает текст по последовательностям пробелом \n",
    " (т.е. даже со второй версией remove_tags всё бы хорошо разделилось)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '', '2', '3']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1  2 3'.split(' ') # NB! .split() и .split(' ') - не одно и тоже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1  2 3'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя',\n",
       " 'заметка',\n",
       " 'будет',\n",
       " 'о',\n",
       " 'сервисе',\n",
       " 'отслеживания',\n",
       " 'активности',\n",
       " 'пользователя',\n",
       " '—',\n",
       " 'CrazyEgg',\n",
       " '.',\n",
       " 'Я',\n",
       " 'не',\n",
       " 'знаю',\n",
       " 'кому',\n",
       " 'обязан',\n",
       " 'сервис',\n",
       " 'таким',\n",
       " 'говорящим',\n",
       " 'именем,']"
      ]
     },
     "execution_count": 1140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большая часть слов отделяется, но знаки препинания лепятся к словам.\n",
    "Можно пройтись по всем словам и убрать из них пунктцацию с методом str.strip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 1124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#основные знаки преминания хранятся в питоноском модуле string.punctuation\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в этом списке не хватает кавычек-ёлочек, лапок, длинного тире и многоточия\n",
    "string.punctuation += '«»—…“”'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя',\n",
       " 'заметка',\n",
       " 'будет',\n",
       " 'о',\n",
       " 'сервисе',\n",
       " 'отслеживания',\n",
       " 'активности',\n",
       " 'пользователя',\n",
       " '',\n",
       " 'CrazyEgg']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word.strip(string.punctuation) for word in text.split()][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так не будут удаляться дефисы и точке в сокращениях, не разделенных пробелом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'как-нибудь'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'как-нибудь'.strip(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'т.е'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'т.е.'.strip(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё слова можно извлечь с помощью простого регулярного выражения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя',\n",
       " 'заметка',\n",
       " 'будет',\n",
       " 'о',\n",
       " 'сервисе',\n",
       " 'отслеживания',\n",
       " 'активности',\n",
       " 'пользователя',\n",
       " 'CrazyEgg',\n",
       " 'Я']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('\\w+', text)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как-нибудь так разделится, но это все-таки не так страшно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё есть готовые токенизаторы из nltk. Они не удаляют пунктуацию, а выделяют её отдельным токеном.\n",
    "\n",
    "Например **wordpunct_tokenizer** разбирает по регулярке - *'\\w+|[^\\w\\s]+'* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя',\n",
       " 'заметка',\n",
       " 'будет',\n",
       " 'о',\n",
       " 'сервисе',\n",
       " 'отслеживания',\n",
       " 'активности',\n",
       " 'пользователя',\n",
       " '—',\n",
       " 'CrazyEgg']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(text)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё есть **word_tokenize**. Он также построен на регулярках, но они там более сложные (учитывается последовательность некоторых \n",
    "символов, символы начала, конца слова и т.д). \n",
    "\n",
    "Специально подобранного под русский язык токенизатора там нет, \n",
    "но и с английским всё работает достаточно хорошо --\n",
    "сокращения типа т.к собираются в один токен, дефисные слова тоже не разделяются, многоточия тут тоже не отделяются, но это можно поправить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя',\n",
       " 'заметка',\n",
       " 'будет',\n",
       " 'о',\n",
       " 'сервисе',\n",
       " 'отслеживания',\n",
       " 'активности',\n",
       " 'пользователя',\n",
       " '—',\n",
       " 'CrazyEgg']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(text)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В генсиме тоже есть функция для токенизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['сегодняшняя',\n",
       " 'заметка',\n",
       " 'будет',\n",
       " 'о',\n",
       " 'сервисе',\n",
       " 'отслеживания',\n",
       " 'активности',\n",
       " 'пользователя',\n",
       " 'crazyegg',\n",
       " 'я']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# опять же, это генератор\n",
    "list(tokenize(text, lowercase=True))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И в razdel тоже есть токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(1, 12, 'Сегодняшняя'),\n",
       " Substring(13, 20, 'заметка'),\n",
       " Substring(21, 26, 'будет'),\n",
       " Substring(27, 28, 'о'),\n",
       " Substring(29, 36, 'сервисе'),\n",
       " Substring(37, 49, 'отслеживания'),\n",
       " Substring(50, 60, 'активности'),\n",
       " Substring(61, 73, 'пользователя'),\n",
       " Substring(74, 75, '—'),\n",
       " Substring(76, 84, 'CrazyEgg')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(razdel_tokenize(text))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Сегодняшняя',\n",
       " 'заметка',\n",
       " 'будет',\n",
       " 'о',\n",
       " 'сервисе',\n",
       " 'отслеживания',\n",
       " 'активности',\n",
       " 'пользователя',\n",
       " '—',\n",
       " 'CrazyEgg']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in list(razdel_tokenize(text))[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нормализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные токены тоже чаще всего нужно привести к какому-то стандартному виду."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое простое и очевидное - привести всё к одному регистру:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'слово'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'СловО'.lower()\n",
    "# если не нужно разбивать на предложения, то это можно сделать в самом начале\n",
    "# text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для языков со слабым словоизменением этого может быть достаточно. Но для русского с его склонениями и спряжениями лучше использовать стемминг или лемматизацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стемминг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стемминг - это урезание слова до его \"основы\" (стема), т.е. такой части, которая является общей для всех словоформ в парадигме слова. По крайней мере так в теории. На практике стемминг сводится к отбрасыванию частотных окончаний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый известный стеммер - стеммер Портера (или snowball стеммер). \n",
    "Подробнее про стеммер Портера можно почитать вот тут - <https://medium.com/@eigenein/стеммер-портера-для-русского-языка-d41c38b2d340>  \n",
    "А совсем подробнее вот тут - <http://snowball.tartarus.org/algorithms/russian/stemmer.html>  \n",
    "Почему он так называется? Так назывался язык программирования, который Портер написал для стеммеров. Язык так называется в созвучие языку SNOBOL. Вот комментарий самого Портера:\n",
    "\n",
    "`Since it effectively provides a ‘suffix STRIPPER GRAMmar’, I had toyed with the idea of calling it ‘strippergram’, but good sense has prevailed, and so it is ‘Snowball’ named as a tribute to SNOBOL, the excellent string handling language of Messrs Farber, Griswold, Poage and Polonsky from the 1960s.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готовые стеммеры для разных языков есть в nltk. Работают они вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Сегодняшняя', 'сегодняшн'),\n",
       " ('заметка', 'заметк'),\n",
       " ('будет', 'будет'),\n",
       " ('о', 'о'),\n",
       " ('сервисе', 'сервис'),\n",
       " ('отслеживания', 'отслеживан'),\n",
       " ('активности', 'активн'),\n",
       " ('пользователя', 'пользовател'),\n",
       " ('—', '—'),\n",
       " ('CrazyEgg', 'CrazyEgg'),\n",
       " ('.', '.'),\n",
       " ('Я', 'я'),\n",
       " ('не', 'не'),\n",
       " ('знаю', 'зна'),\n",
       " ('кому', 'ком'),\n",
       " ('обязан', 'обяза'),\n",
       " ('сервис', 'сервис'),\n",
       " ('таким', 'так'),\n",
       " ('говорящим', 'говоря'),\n",
       " ('именем', 'имен'),\n",
       " (',', ','),\n",
       " ('но', 'но'),\n",
       " ('оно', 'он'),\n",
       " ('работает', 'работа'),\n",
       " (',', ','),\n",
       " ('и', 'и'),\n",
       " ('хорошо', 'хорош'),\n",
       " ('.', '.'),\n",
       " ('Запоминается', 'запомина'),\n",
       " ('?', '?')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(word, stemmer.stem(word)) for word in word_tokenize(text)][:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недостатки стемминга достаточно очевидные:  \n",
    "1) с супплетивными формами или редкими окончаниями слова стемминг работать не умеет  \n",
    "2) к одной основе могут приводится разные слова  \n",
    "3) к разным основам могут сводиться формы одного слова  \n",
    "4) приставки не отбрасываются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'прол'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"пролить\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'прольет'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"прольёт\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'прол'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"пролом\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизация - это замена словоформы слова в парадигме на какую-то заранее выбранную стадартную форму (лемму). \n",
    "\n",
    "\n",
    "\n",
    "Например, для разных форм глагола леммой обычно является неопределенная форма, а для существительного форма мужского рода единственного числа. Это позволяет избавиться от недостатков стемминга (будет, был - одна лемма), (пролить, пролом - разные). Однако лемматизация значительно сложнее. \n",
    "\n",
    "\\* - (Значения слов \"слово\", \"слоформа\", \"парадигма\" приблизительно соответствует тому, которое использует Зализняк вот тут - http://inslav.ru/images/stories/pdf/2002_Zalizniak_RIS_i_statji.pdf (стр. 21-22)) Но это на самом деле не важно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К счастью есть готовые хорошие лемматизаторы. Для русского основых варианта два: Mystem и Pymorphy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Майстем работает немного лучше и сам токенизирует,\n",
    "поэтому можно в него засовывать сырой текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', 'сегодняшний', ' ', 'заметка', ' ', 'быть', ' ', 'о', ' ', 'сервис']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mystem.lemmatize функция лемматизации в майстеме\n",
    "# сам объект mystem нужно заранее инициализировать\n",
    "# мы сделали это в начале тетрадки строчкой \"mystem = Mystem()\"\n",
    "mystem.lemmatize(text)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'Сегодняшняя заметка будет о сервисе отслеживания активности пользователя — CrazyEgg. Я не знаю кому обязан сервис таким говорящим именем, но оно работает, и хорошо.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужна грамматическая информация или надо сохранить ненормализованный текст,\n",
    "# есть функция mystem.analyze\n",
    "words_analized = mystem.analyze(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '\\n'},\n",
       " {'analysis': [{'lex': 'сегодняшний', 'wt': 1, 'gr': 'A=им,ед,полн,жен'}],\n",
       "  'text': 'Сегодняшняя'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'заметка', 'wt': 1, 'gr': 'S,жен,неод=им,ед'}],\n",
       "  'text': 'заметка'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'быть',\n",
       "    'wt': 0.1492564349,\n",
       "    'gr': 'V,нп=непрош,ед,изъяв,3-л'}],\n",
       "  'text': 'будет'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'о', 'wt': 0.9737875835, 'gr': 'PR='}], 'text': 'о'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'сервис', 'wt': 1, 'gr': 'S,муж,неод=пр,ед'}],\n",
       "  'text': 'сервисе'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'отслеживание',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,сред,неод=(вин,мн|род,ед|им,мн)'}],\n",
       "  'text': 'отслеживания'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'активность',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,жен,неод=(пр,ед|вин,мн|дат,ед|род,ед|им,мн)'}],\n",
       "  'text': 'активности'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'пользователь',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,муж,од=(вин,ед|род,ед)'}],\n",
       "  'text': 'пользователя'},\n",
       " {'text': ' — <'},\n",
       " {'analysis': [], 'text': 'a'},\n",
       " {'text': ' '},\n",
       " {'analysis': [], 'text': 'href'},\n",
       " {'text': '=\"'},\n",
       " {'analysis': [], 'text': 'http'},\n",
       " {'text': '://'},\n",
       " {'analysis': [], 'text': 'www'},\n",
       " {'text': '.'},\n",
       " {'analysis': [], 'text': 'crazyegg'},\n",
       " {'text': '.'},\n",
       " {'analysis': [], 'text': 'com'},\n",
       " {'text': '\" '},\n",
       " {'analysis': [], 'text': 'title'},\n",
       " {'text': '=\"'},\n",
       " {'analysis': [{'lex': 'сумасшедший',\n",
       "    'wt': 0.9962116609,\n",
       "    'gr': 'A=(вин,мн,полн,неод|им,мн,полн)'}],\n",
       "  'text': 'Сумасшедшие'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'яйцо',\n",
       "    'wt': 1,\n",
       "    'gr': 'S,сред,неод=(вин,мн|род,ед|им,мн)'}],\n",
       "  'text': 'яйца'},\n",
       " {'text': '\">'},\n",
       " {'analysis': [], 'text': 'CrazyEgg'},\n",
       " {'text': '</'},\n",
       " {'analysis': [], 'text': 'a'},\n",
       " {'text': '>'},\n",
       " {'text': '. '},\n",
       " {'analysis': [{'lex': 'я', 'wt': 0.9999716281, 'gr': 'SPRO,ед,1-л=им'}],\n",
       "  'text': 'Я'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'знать',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,несов,пе=непрош,ед,изъяв,1-л'}],\n",
       "  'text': 'знаю'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'кто', 'wt': 0.9879970317, 'gr': 'SPRO,ед,муж,од=дат'}],\n",
       "  'text': 'кому'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'обязанный', 'wt': 0.9785135224, 'gr': 'A=ед,кр,муж'}],\n",
       "  'text': 'обязан'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'сервис', 'wt': 1, 'gr': 'S,муж,неод=(вин,ед|им,ед)'}],\n",
       "  'text': 'сервис'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'такой',\n",
       "    'wt': 1,\n",
       "    'gr': 'APRO=(дат,мн|твор,ед,муж|твор,ед,сред)'}],\n",
       "  'text': 'таким'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'говорящий',\n",
       "    'wt': 0.1808014961,\n",
       "    'gr': 'A=(дат,мн,полн|твор,ед,полн,муж|твор,ед,полн,сред)'}],\n",
       "  'text': 'говорящим'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'имя', 'wt': 1, 'gr': 'S,сред,неод=твор,ед'}],\n",
       "  'text': 'именем'},\n",
       " {'text': ', '},\n",
       " {'analysis': [{'lex': 'но', 'wt': 0.9998906299, 'gr': 'CONJ='}],\n",
       "  'text': 'но'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'оно',\n",
       "    'wt': 0.9980605704,\n",
       "    'gr': 'SPRO,ед,3-л,сред=им'}],\n",
       "  'text': 'оно'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'работать',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,несов,нп=непрош,ед,изъяв,3-л'}],\n",
       "  'text': 'работает'},\n",
       " {'text': ', '},\n",
       " {'analysis': [{'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='}], 'text': 'и'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'хорошо', 'wt': 0.0008292704217, 'gr': 'ADV=вводн'}],\n",
       "  'text': 'хорошо'},\n",
       " {'text': '. '},\n",
       " {'analysis': [{'lex': 'запоминаться',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,нп=непрош,ед,изъяв,3-л,несов'}],\n",
       "  'text': 'Запоминается'},\n",
       " {'text': '? '},\n",
       " {'analysis': [{'lex': 'отлично', 'wt': 0.9652969484, 'gr': 'ADV='}],\n",
       "  'text': 'Отлично'},\n",
       " {'text': '!'},\n",
       " {'text': '<'},\n",
       " {'analysis': [], 'text': 'br'},\n",
       " {'text': '><'},\n",
       " {'analysis': [], 'text': 'br'},\n",
       " {'text': '><'},\n",
       " {'analysis': [], 'text': 'img'},\n",
       " {'text': ' '},\n",
       " {'analysis': [], 'text': 'src'},\n",
       " {'text': '=\"'},\n",
       " {'analysis': [], 'text': 'http'},\n",
       " {'text': '://'},\n",
       " {'text': 'img172'},\n",
       " {'text': '.'},\n",
       " {'analysis': [], 'text': 'imageshack'},\n",
       " {'text': '.'},\n",
       " {'analysis': [], 'text': 'us'},\n",
       " {'text': '/'},\n",
       " {'text': 'img172'},\n",
       " {'text': '/'},\n",
       " {'text': '8434'},\n",
       " {'text': '/'},\n",
       " {'text': '18274658kc4'},\n",
       " {'text': '.'},\n",
       " {'analysis': [], 'text': 'png'},\n",
       " {'text': '\" '},\n",
       " {'analysis': [], 'text': 'alt'},\n",
       " {'text': '=\"'},\n",
       " {'analysis': [{'lex': 'сумасшедший',\n",
       "    'wt': 1,\n",
       "    'gr': 'A=(вин,ед,полн,сред|им,ед,полн,сред)'}],\n",
       "  'text': 'Сумасшедшее'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# возвращает она список словарей\n",
    "# каждый словарь имеет либо одно поле 'text' (когда попался пробел) или text и analysis\n",
    "# в analysis снова список словарей с вариантами разбора (первый самый вероятный)\n",
    "# поля в analysis - 'gr' - грамматическая информация, 'lex' - лемма\n",
    "# analysis - может быть пустым списком\n",
    "words_analized[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово -  Сегодняшняя\n",
      "Разбор слова -  {'lex': 'сегодняшний', 'wt': 1, 'gr': 'A=им,ед,полн,жен'}\n",
      "Лемма слова -  сегодняшний\n",
      "Грамматическая информация слова -  A=им,ед,полн,жен\n"
     ]
    }
   ],
   "source": [
    "print('Слово - ', words_analized[1]['text'])\n",
    "print('Разбор слова - ', words_analized[1]['analysis'][0])\n",
    "print('Лемма слова - ', words_analized[1]['analysis'][0]['lex'])\n",
    "print('Грамматическая информация слова - ', words_analized[1]['analysis'][0]['gr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['сегодняшний',\n",
       " 'заметка',\n",
       " 'быть',\n",
       " 'о',\n",
       " 'сервис',\n",
       " 'отслеживание',\n",
       " 'активность',\n",
       " 'пользователь',\n",
       " 'я',\n",
       " 'не']"
      ]
     },
     "execution_count": 1137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#леммы можно достать в одну строчку\n",
    "[parse['analysis'][0]['lex'] for parse in words_analized if parse.get('analysis')][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mystem умеет разбивать текст на предложения, но через питоновский интерфейс это сделать не получится. Нужно скачать mystem отсюда - https://yandex.ru/dev/mystem/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После этого сохранить текст в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('text.txt', 'w')\n",
    "f.write(text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из командной строки или из питона запустить майстем на нашем файле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# про параметры почитайте в ./mystem -h\n",
    "!mystem -iscd --format json text.txt text_parsed.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целевом файле теперь лежит разобранный текст в jsonlines (json на каждой строчке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "t = [json.loads(line) for line in open('text_parsed.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'analysis': [{'lex': 'сегодняшний', 'gr': 'A=им,ед,полн,жен'}],\n",
       "   'text': 'Сегодняшняя'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'заметка', 'gr': 'S,жен,неод=им,ед'}],\n",
       "   'text': 'заметка'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'быть', 'gr': 'V,нп=непрош,ед,изъяв,3-л'}],\n",
       "   'text': 'будет'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'о', 'gr': 'PR='}], 'text': 'о'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'сервис', 'gr': 'S,муж,неод=пр,ед'}],\n",
       "   'text': 'сервисе'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'отслеживание', 'gr': 'S,сред,неод=вин,мн'},\n",
       "    {'lex': 'отслеживание', 'gr': 'S,сред,неод=род,ед'},\n",
       "    {'lex': 'отслеживание', 'gr': 'S,сред,неод=им,мн'}],\n",
       "   'text': 'отслеживания'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'активность', 'gr': 'S,жен,неод=пр,ед'},\n",
       "    {'lex': 'активность', 'gr': 'S,жен,неод=вин,мн'},\n",
       "    {'lex': 'активность', 'gr': 'S,жен,неод=дат,ед'},\n",
       "    {'lex': 'активность', 'gr': 'S,жен,неод=род,ед'},\n",
       "    {'lex': 'активность', 'gr': 'S,жен,неод=им,мн'}],\n",
       "   'text': 'активности'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'пользователь', 'gr': 'S,муж,од=вин,ед'},\n",
       "    {'lex': 'пользователь', 'gr': 'S,муж,од=род,ед'}],\n",
       "   'text': 'пользователя'},\n",
       "  {'text': ' —  '},\n",
       "  {'analysis': [], 'text': 'CrazyEgg'},\n",
       "  {'text': ' '},\n",
       "  {'text': '. '},\n",
       "  {'text': '\\\\s'},\n",
       "  {'analysis': [{'lex': 'я', 'gr': 'SPRO,ед,1-л=им'}], 'text': 'Я'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'не', 'gr': 'PART='}], 'text': 'не'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'знать', 'gr': 'V,несов,пе=непрош,ед,изъяв,1-л'}],\n",
       "   'text': 'знаю'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'кто', 'gr': 'SPRO,ед,муж,од=дат'}], 'text': 'кому'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'обязанный', 'gr': 'A=ед,кр,муж'}], 'text': 'обязан'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'сервис', 'gr': 'S,муж,неод=вин,ед'},\n",
       "    {'lex': 'сервис', 'gr': 'S,муж,неод=им,ед'}],\n",
       "   'text': 'сервис'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'такой', 'gr': 'APRO=дат,мн'},\n",
       "    {'lex': 'такой', 'gr': 'APRO=твор,ед,муж'},\n",
       "    {'lex': 'такой', 'gr': 'APRO=твор,ед,сред'}],\n",
       "   'text': 'таким'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'говорящий', 'gr': 'A=дат,мн,полн'},\n",
       "    {'lex': 'говорящий', 'gr': 'A=твор,ед,полн,муж'},\n",
       "    {'lex': 'говорящий', 'gr': 'A=твор,ед,полн,сред'}],\n",
       "   'text': 'говорящим'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'имя', 'gr': 'S,сред,неод=твор,ед'}],\n",
       "   'text': 'именем'},\n",
       "  {'text': ', '},\n",
       "  {'analysis': [{'lex': 'но', 'gr': 'CONJ='}], 'text': 'но'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'оно', 'gr': 'SPRO,ед,3-л,сред=им'}], 'text': 'оно'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'работать', 'gr': 'V,несов,нп=непрош,ед,изъяв,3-л'}],\n",
       "   'text': 'работает'},\n",
       "  {'text': ', '},\n",
       "  {'analysis': [{'lex': 'и', 'gr': 'CONJ='}], 'text': 'и'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'хорошо', 'gr': 'ADV=вводн'}], 'text': 'хорошо'},\n",
       "  {'text': '. '},\n",
       "  {'text': '\\\\s'},\n",
       "  {'analysis': [{'lex': 'запоминаться',\n",
       "     'gr': 'V,нп=непрош,ед,изъяв,3-л,несов'}],\n",
       "   'text': 'Запоминается'},\n",
       "  {'text': '? '},\n",
       "  {'text': '\\\\s'},\n",
       "  {'analysis': [{'lex': 'отлично', 'gr': 'ADV='}], 'text': 'Отлично'},\n",
       "  {'text': '!       '},\n",
       "  {'text': '\\\\s'},\n",
       "  {'analysis': [{'lex': 'что', 'gr': 'SPRO,ед,сред,неод=вин'},\n",
       "    {'lex': 'что', 'gr': 'SPRO,ед,сред,неод=им'}],\n",
       "   'text': 'Что'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'это', 'gr': 'SPRO,ед,сред,неод=вин'},\n",
       "    {'lex': 'это', 'gr': 'SPRO,ед,сред,неод=им'}],\n",
       "   'text': 'это'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'такой', 'gr': 'APRO=вин,ед,сред'},\n",
       "    {'lex': 'такой', 'gr': 'APRO=им,ед,сред'}],\n",
       "   'text': 'такое'},\n",
       "  {'text': '?'},\n",
       "  {'text': '  \\n'}],\n",
       " [{'analysis': [{'lex': 'как', 'gr': 'ADVPRO='}], 'text': 'Как'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'уже', 'gr': 'ADV='}], 'text': 'уже'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'сказать',\n",
       "     'gr': 'V,сов,пе=прош,ед,прич,кр,сред,страд'}],\n",
       "   'text': 'сказано'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'выше', 'gr': 'ADV='}], 'text': 'выше'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'это', 'gr': 'SPRO,ед,сред,неод=вин'},\n",
       "    {'lex': 'это', 'gr': 'SPRO,ед,сред,неод=им'}],\n",
       "   'text': 'это'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'сервис', 'gr': 'S,муж,неод=вин,ед'},\n",
       "    {'lex': 'сервис', 'gr': 'S,муж,неод=им,ед'}],\n",
       "   'text': 'сервис'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'для', 'gr': 'PR='}], 'text': 'для'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'отслеживание', 'gr': 'S,сред,неод=вин,мн'},\n",
       "    {'lex': 'отслеживание', 'gr': 'S,сред,неод=род,ед'},\n",
       "    {'lex': 'отслеживание', 'gr': 'S,сред,неод=им,мн'}],\n",
       "   'text': 'отслеживания'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'перемещение', 'gr': 'S,сред,неод=вин,мн'},\n",
       "    {'lex': 'перемещение', 'gr': 'S,сред,неод=род,ед'},\n",
       "    {'lex': 'перемещение', 'gr': 'S,сред,неод=им,мн'}],\n",
       "   'text': 'перемещения'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'пользователь', 'gr': 'S,муж,од=вин,мн'},\n",
       "    {'lex': 'пользователь', 'gr': 'S,муж,од=род,мн'}],\n",
       "   'text': 'пользователей'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'по', 'gr': 'PR='}], 'text': 'по'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'сайт', 'gr': 'S,муж,неод=дат,ед'}], 'text': 'сайту'},\n",
       "  {'text': ' — '},\n",
       "  {'analysis': [{'lex': 'кто', 'gr': 'SPRO,ед,муж,од=им'}], 'text': 'кто'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'куда', 'gr': 'ADVPRO='}], 'text': 'куда'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'кликнуть', 'gr': 'V,сов,пе=прош,ед,изъяв,муж'}],\n",
       "   'text': 'кликнул'},\n",
       "  {'text': ', '},\n",
       "  {'analysis': [{'lex': 'какой', 'gr': 'APRO=им,мн'},\n",
       "    {'lex': 'какой', 'gr': 'APRO=вин,мн,неод'}],\n",
       "   'text': 'какие'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'ссылка', 'gr': 'S,жен,неод=вин,мн'},\n",
       "    {'lex': 'ссылка', 'gr': 'S,жен,неод=род,ед'},\n",
       "    {'lex': 'ссылка', 'gr': 'S,жен,неод=им,мн'}],\n",
       "   'text': 'ссылки'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'наиболее', 'gr': 'ADV='}], 'text': 'наиболее'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'популярный', 'gr': 'A=вин,мн,полн,неод'},\n",
       "    {'lex': 'популярный', 'gr': 'A=им,мн,полн'}],\n",
       "   'text': 'популярные'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'и', 'gr': 'CONJ='}], 'text': 'и'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'тот', 'gr': 'APRO=дат,ед,муж'},\n",
       "    {'lex': 'тот', 'gr': 'APRO=дат,ед,сред'}],\n",
       "   'text': 'тому'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'подобный', 'gr': 'A=им,ед,полн,жен'}],\n",
       "   'text': 'подобная'},\n",
       "  {'text': ', '},\n",
       "  {'analysis': [{'lex': 'разнородный', 'gr': 'A=им,ед,полн,жен'}],\n",
       "   'text': 'разнородная'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'информация', 'gr': 'S,жен,неод=им,ед'}],\n",
       "   'text': 'информация'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'для', 'gr': 'PR='}], 'text': 'для'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'юзабилист',\n",
       "     'qual': 'bastard',\n",
       "     'gr': 'S,муж,од=вин,мн'},\n",
       "    {'lex': 'юзабилист', 'qual': 'bastard', 'gr': 'S,муж,од=род,мн'}],\n",
       "   'text': 'юзабилистов'},\n",
       "  {'text': '.'},\n",
       "  {'text': ' \\n'}],\n",
       " [{'analysis': [{'lex': 'сервис', 'gr': 'S,муж,неод=вин,ед'},\n",
       "    {'lex': 'сервис', 'gr': 'S,муж,неод=им,ед'}],\n",
       "   'text': 'Сервис'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'позволять', 'gr': 'V,пе=непрош,ед,изъяв,3-л,несов'}],\n",
       "   'text': 'позволяет'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'отслеживать', 'gr': 'V=инф,несов,пе'}],\n",
       "   'text': 'отслеживать'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'активность', 'gr': 'S,жен,неод=вин,ед'},\n",
       "    {'lex': 'активность', 'gr': 'S,жен,неод=им,ед'}],\n",
       "   'text': 'активность'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'определенный', 'gr': 'A=пр,мн,полн'},\n",
       "    {'lex': 'определенный', 'gr': 'A=вин,мн,полн,од'},\n",
       "    {'lex': 'определенный', 'gr': 'A=род,мн,полн'}],\n",
       "   'text': 'определенных'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'пользователь', 'gr': 'S,муж,од=вин,мн'},\n",
       "    {'lex': 'пользователь', 'gr': 'S,муж,од=род,мн'}],\n",
       "   'text': 'пользователей'},\n",
       "  {'text': ', '},\n",
       "  {'analysis': [{'lex': 'и', 'gr': 'CONJ='}], 'text': 'и'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'выводить', 'gr': 'V=инф,несов,пе'}],\n",
       "   'text': 'выводить'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'этот', 'gr': 'APRO=им,мн'},\n",
       "    {'lex': 'этот', 'gr': 'APRO=вин,мн,неод'}],\n",
       "   'text': 'эти'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'данные', 'gr': 'S,мн,неод=вин'},\n",
       "    {'lex': 'данные', 'gr': 'S,мн,неод=им'}],\n",
       "   'text': 'данные'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'в', 'gr': 'PR='}], 'text': 'в'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'различный', 'gr': 'A=пр,мн,полн'},\n",
       "    {'lex': 'различный', 'gr': 'A=вин,мн,полн,од'},\n",
       "    {'lex': 'различный', 'gr': 'A=род,мн,полн'}],\n",
       "   'text': 'различных'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'форма', 'gr': 'S,жен,неод=пр,мн'}], 'text': 'формах'},\n",
       "  {'text': ': «'},\n",
       "  {'analysis': [{'lex': 'инфракрасный', 'gr': 'A=им,ед,полн,жен'}],\n",
       "   'text': 'инфракрасная'},\n",
       "  {'text': '» — '},\n",
       "  {'analysis': [{'lex': 'где', 'gr': 'ADVPRO='}], 'text': 'где'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'чем', 'gr': 'CONJ='}], 'text': 'чем'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'активно', 'gr': 'ADV=срав'}], 'text': 'активнее'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'область', 'gr': 'S,жен,неод=вин,ед'},\n",
       "    {'lex': 'область', 'gr': 'S,жен,неод=им,ед'}],\n",
       "   'text': 'область'},\n",
       "  {'text': ', '},\n",
       "  {'analysis': [{'lex': 'тем', 'gr': 'CONJ='}], 'text': 'тем'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'она', 'gr': 'SPRO,ед,3-л,жен=им'}], 'text': 'она'},\n",
       "  {'text': ' «'},\n",
       "  {'analysis': [{'lex': 'тепло', 'gr': 'ADV=срав'}], 'text': 'теплее'},\n",
       "  {'text': '», '},\n",
       "  {'analysis': [{'lex': 'салют', 'gr': 'S,муж,неод=вин,мн'},\n",
       "    {'lex': 'салют', 'gr': 'S,муж,неод=им,мн'}],\n",
       "   'text': 'салюты'},\n",
       "  {'text': ' ('},\n",
       "  {'analysis': [{'lex': 'чем', 'gr': 'CONJ='}], 'text': 'чем'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'активно', 'gr': 'ADV=срав'}], 'text': 'активнее'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'область', 'gr': 'S,жен,неод=вин,ед'},\n",
       "    {'lex': 'область', 'gr': 'S,жен,неод=им,ед'}],\n",
       "   'text': 'область'},\n",
       "  {'text': ', '},\n",
       "  {'analysis': [{'lex': 'тем', 'gr': 'CONJ='}], 'text': 'тем'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'много', 'gr': 'ADV=срав'}], 'text': 'больше'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'конфеть',\n",
       "     'qual': 'bastard',\n",
       "     'gr': 'S,жен,неод=пр,ед'},\n",
       "    {'lex': 'конфеть', 'qual': 'bastard', 'gr': 'S,жен,неод=вин,мн'},\n",
       "    {'lex': 'конфеть', 'qual': 'bastard', 'gr': 'S,жен,неод=дат,ед'},\n",
       "    {'lex': 'конфеть', 'qual': 'bastard', 'gr': 'S,жен,неод=род,ед'},\n",
       "    {'lex': 'конфеть', 'qual': 'bastard', 'gr': 'S,жен,неод=им,мн'}],\n",
       "   'text': 'конфети'},\n",
       "  {'text': '), '},\n",
       "  {'analysis': [{'lex': 'простой', 'gr': 'A=вин,ед,полн,муж,неод'},\n",
       "    {'lex': 'простой', 'gr': 'A=им,ед,полн,муж'},\n",
       "    {'lex': 'простой', 'gr': 'A=пр,ед,полн,жен'},\n",
       "    {'lex': 'простой', 'gr': 'A=дат,ед,полн,жен'},\n",
       "    {'lex': 'простой', 'gr': 'A=род,ед,полн,жен'},\n",
       "    {'lex': 'простой', 'gr': 'A=твор,ед,полн,жен'}],\n",
       "   'text': 'простой'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'список', 'gr': 'S,муж,неод=вин,ед'},\n",
       "    {'lex': 'список', 'gr': 'S,муж,неод=им,ед'}],\n",
       "   'text': 'список'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'с', 'gr': 'PR='}], 'text': 'с'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'сортировка', 'gr': 'S,жен,неод=твор,ед'}],\n",
       "   'text': 'сортировкой'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'по', 'gr': 'PR='}], 'text': 'по'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'активность', 'gr': 'S,жен,неод=пр,ед'},\n",
       "    {'lex': 'активность', 'gr': 'S,жен,неод=вин,мн'},\n",
       "    {'lex': 'активность', 'gr': 'S,жен,неод=дат,ед'},\n",
       "    {'lex': 'активность', 'gr': 'S,жен,неод=род,ед'},\n",
       "    {'lex': 'активность', 'gr': 'S,жен,неод=им,мн'}],\n",
       "   'text': 'активности'},\n",
       "  {'text': ', '},\n",
       "  {'analysis': [{'lex': 'колба', 'gr': 'S,жен,неод=вин,мн'},\n",
       "    {'lex': 'колба', 'gr': 'S,жен,неод=род,ед'},\n",
       "    {'lex': 'колба', 'gr': 'S,жен,неод=им,мн'}],\n",
       "   'text': 'колбы'},\n",
       "  {'text': ' ('},\n",
       "  {'analysis': [{'lex': 'чем', 'gr': 'CONJ='}], 'text': 'чем'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'заполненный', 'qual': 'bastard', 'gr': 'A=срав'}],\n",
       "   'text': 'заполненнее'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'колба', 'gr': 'S,жен,неод=им,ед'}], 'text': 'колба'},\n",
       "  {'text': ', '},\n",
       "  {'analysis': [{'lex': 'тем', 'gr': 'CONJ='}], 'text': 'тем'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'активно', 'gr': 'ADV=срав'}], 'text': 'активнее'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'область', 'gr': 'S,жен,неод=вин,ед'},\n",
       "    {'lex': 'область', 'gr': 'S,жен,неод=им,ед'}],\n",
       "   'text': 'область'},\n",
       "  {'text': '), '},\n",
       "  {'analysis': [{'lex': 'облако', 'gr': 'S,сред,неод=вин,мн'},\n",
       "    {'lex': 'облако', 'gr': 'S,сред,неод=род,ед'},\n",
       "    {'lex': 'облако', 'gr': 'S,сред,неод=им,мн'}],\n",
       "   'text': 'облака'},\n",
       "  {'text': ' ('},\n",
       "  {'analysis': [{'lex': 'на', 'gr': 'PR='}], 'text': 'на'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'мой', 'gr': 'APRO=вин,ед,муж,неод'},\n",
       "    {'lex': 'мой', 'gr': 'APRO=им,ед,муж'}],\n",
       "   'text': 'мой'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'взгляд', 'gr': 'S,муж,неод=вин,ед'},\n",
       "    {'lex': 'взгляд', 'gr': 'S,муж,неод=им,ед'}],\n",
       "   'text': 'взгляд'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'наиболее', 'gr': 'ADV='}], 'text': 'наиболее'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'удобный', 'gr': 'A=вин,ед,полн,муж,неод'},\n",
       "    {'lex': 'удобный', 'gr': 'A=им,ед,полн,муж'}],\n",
       "   'text': 'удобный'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'вариант', 'gr': 'S,муж,неод=вин,ед'},\n",
       "    {'lex': 'вариант', 'gr': 'S,муж,неод=им,ед'}],\n",
       "   'text': 'вариант'},\n",
       "  {'text': ' — '},\n",
       "  {'analysis': [{'lex': 'совмещать', 'gr': 'V=непрош,ед,изъяв,3-л,несов,пе'}],\n",
       "   'text': 'совмещает'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'в', 'gr': 'PR='}], 'text': 'в'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'себя', 'gr': 'SPRO=пр'},\n",
       "    {'lex': 'себя', 'gr': 'SPRO=дат'}],\n",
       "   'text': 'себе'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'весь', 'gr': 'APRO=им,мн'},\n",
       "    {'lex': 'весь', 'gr': 'APRO=вин,ед,сред'},\n",
       "    {'lex': 'весь', 'gr': 'APRO=им,ед,сред'},\n",
       "    {'lex': 'весь', 'gr': 'APRO=вин,мн,неод'}],\n",
       "   'text': 'все'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'остальной', 'gr': 'APRO=им,мн'},\n",
       "    {'lex': 'остальной', 'gr': 'APRO=вин,мн,неод'}],\n",
       "   'text': 'остальные'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'вместе', 'gr': 'ADV='}], 'text': 'вместе'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'взять',\n",
       "     'gr': 'V,сов,пе=прош,вин,мн,прич,полн,страд,неод'},\n",
       "    {'lex': 'взять', 'gr': 'V,сов,пе=прош,им,мн,прич,полн,страд'}],\n",
       "   'text': 'взятые'},\n",
       "  {'text': ')'},\n",
       "  {'text': '.             '},\n",
       "  {'text': '\\\\s'},\n",
       "  {'analysis': [{'lex': 'для', 'gr': 'PR='}], 'text': 'Для'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'кто', 'gr': 'SPRO,ед,муж,од=вин'},\n",
       "    {'lex': 'кто', 'gr': 'SPRO,ед,муж,од=род'}],\n",
       "   'text': 'кого'},\n",
       "  {'text': ' '},\n",
       "  {'analysis': [{'lex': 'это', 'gr': 'SPRO,ед,сред,неод=вин'},\n",
       "    {'lex': 'это', 'gr': 'SPRO,ед,сред,неод=им'}],\n",
       "   'text': 'это'},\n",
       "  {'text': '?'},\n",
       "  {'text': '  \\n'}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый объект в этом списке - параграф. Каждый параграф на предложения можно разбив по тегу '//s'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё так вызывать майстем может понадобиться, если важна скорость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недостатки Mystem: это продукт Яндекса с некоторыми ограничениями на использование, больше он не развивается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важным достоинством Mystem является то, что он работает не с отдельными словами, а с целым предложением. При определении нужной леммы учитывается контекст, что позволяет во многих случаях разрешать омонимию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pymorphy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pymorphy - открытый и развивается (можно поучаствовать на гитхабе)\n",
    "\n",
    "Ссылка на репозиторий: https://github.com/kmike/pymorphy2\n",
    "\n",
    "Попробуйте сразу установить быструю версию (pip install pymorphy2[fast])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У него нет втстроенной токенизации и он расценивает всё как слово. Когда есть несколько вариантов, он выдает их с вероятностостями, которые расчитатны на корпусе со снятой неоднозначностью. Это лучше стемминга, но хуже майстема."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# основная функция - pymorphy.parse\n",
    "words_analized = [morph.parse(token) for token in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='печь', tag=OpencorporaTag('INFN,impf,tran'), normal_form='печь', score=0.666666, methods_stack=((<DictionaryAnalyzer>, 'печь', 2352, 0),)),\n",
       " Parse(word='печь', tag=OpencorporaTag('NOUN,inan,femn sing,nomn'), normal_form='печь', score=0.166666, methods_stack=((<DictionaryAnalyzer>, 'печь', 2131, 0),)),\n",
       " Parse(word='печь', tag=OpencorporaTag('NOUN,inan,femn sing,accs'), normal_form='печь', score=0.166666, methods_stack=((<DictionaryAnalyzer>, 'печь', 2131, 3),))]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph.parse(\"печь\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первое слово -  сегодняшняя\n",
      "Разбор первого слова -  Parse(word='сегодняшняя', tag=OpencorporaTag('ADJF femn,sing,nomn'), normal_form='сегодняшний', score=1.0, methods_stack=((<DictionaryAnalyzer>, 'сегодняшняя', 382, 7),))\n",
      "Лемма первого слова -  сегодняшний\n",
      "Грамматическая информация первого слова -  ADJF femn,sing,nomn\n",
      "Часть речи первого слова -  ADJF\n",
      "Род первого слова -  femn\n",
      "Число первого слова -  sing\n",
      "Падеж первого слова -  nomn\n"
     ]
    }
   ],
   "source": [
    "# Она похожа на analyze в майстеме только возрващает список объектов Parse\n",
    "# Первый в списке - самый вероятный разбор (у каждого есть score)\n",
    "# Информация достается через атрибут (Parse.word - например)\n",
    "# Грамматическая информация хранится в объекте OpencorporaTag и из него удобно доставать\n",
    "# части речи или другие категории\n",
    "print('Первое слово - ', words_analized[0][0].word)\n",
    "print('Разбор первого слова - ', words_analized[0][0])\n",
    "print('Лемма первого слова - ', words_analized[0][0].normal_form)\n",
    "print('Грамматическая информация первого слова - ', words_analized[0][0].tag)\n",
    "print('Часть речи первого слова - ', words_analized[0][0].tag.POS)\n",
    "print('Род первого слова - ', words_analized[0][0].tag.gender)\n",
    "print('Число первого слова - ', words_analized[0][0].tag.number)\n",
    "print('Падеж первого слова - ', words_analized[0][0].tag.case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительная очистка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пунктуация часто совсем не нужна и поэтому можно выбросить её заранее. Если нужно обрабатывать много текста, это может немного ускорить процесс.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['в',\n",
       " 'это',\n",
       " 'случай',\n",
       " 'слово',\n",
       " 'вроде',\n",
       " 'и',\n",
       " 'не',\n",
       " 'пройти',\n",
       " 'фильтр',\n",
       " 'и',\n",
       " 'быть',\n",
       " 'удалить']"
      ]
     },
     "execution_count": 1154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оставим только буквено-численные токены\n",
    "# Это не самый лучший вариант, так как удалятся сокращения с точкой, слова через дефис\n",
    "text = 'В этом случае слова вроде т.к. и по-другому не пройдут фильтр и будут удалены.'\n",
    "good_tokens = [word for word in word_tokenize(text) if word.isalnum()]\n",
    "[morph.parse(token)[0].normal_form for token in good_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['сегодняшний',\n",
       " 'заметка',\n",
       " 'быть',\n",
       " 'сервис',\n",
       " 'отслеживание',\n",
       " 'активность',\n",
       " 'пользователь',\n",
       " 'crazyegg',\n",
       " 'знать',\n",
       " 'кома']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#можно сделать фильтр по длине\n",
    "good_tokens = [word.strip(string.punctuation) for word in \n",
    "               word_tokenize(text) \n",
    "               if len(word) > 2 and len(word) < 35]\n",
    "\n",
    "[morph.parse(token)[0].normal_form for token in good_tokens][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно убрать стоп-слова (предлоги, союзы, местоимения, частотные слова). Сам термин стоп-слово происходит из информационного поиска, первый раз его упомянул [Питер Лун](https://en.wikipedia.org/wiki/Hans_Peter_Luhn) в 1959.  \n",
    "Удаление таких слов позволяло сократить размер индекса и не сильно испортить выдачу или даже улучшить её, поднимая релевантность документам со значимыми словами. Со временем от такой практики, в основном, отказались - память стала дешевой (и повились всякие алгоритмы для сокращения потребления памяти), а для учёта значимости придумали IDF.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во многих поисковых движках стоп-слова всё ещё используются. Часто их используют и в практических задачах (классификации, тематическом моделировании). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "# стоп-слова есть в nltk\n",
    "stops = stopwords.words('russian')\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список не идеальный и его можно расширять под свои задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['это',\n",
       " 'случай',\n",
       " 'слово',\n",
       " 'вроде',\n",
       " 'т.к',\n",
       " 'по-другому',\n",
       " 'пройти',\n",
       " 'фильтр',\n",
       " 'удалить']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_normalized = [morph.parse(token)[0].normal_form for token in good_tokens]\n",
    "[word for word in words_normalized if word not in stops]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка для других языков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скорее всего вы будете работать в основном только с русским языком. Но знать, чем пользоваться для других на всякий случай - тоже полезно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nltk и gensim по умолчанию адаптированы под английский язык, поэтому разбирать их еще раз не будем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть еще одна библиотека, про которую стоит рассказать - [**SpaCy**](https://spacy.io/). Это многоцелевая многоязычная библиотека. Если вам понадобится серьезно работать с английским, то лучшим вариантом будет использовать SpaCy. Другие языки там тоже поддерживаются (см. документацию - ), но не настолько хорошо как английский язык. \n",
    "\n",
    "В SpaCy много всего и мы будем возвращаться к ней по ходу курса. Пока посмотрим на интрументы базовой предобработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (2.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: thinc==7.4.1 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy) (7.4.1)\n",
      "Requirement already satisfied: setuptools in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy) (41.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy) (4.46.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/mnefedov/.pyenv/versions/3.6.5/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: en_core_web_sm==2.3.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.0/en_core_web_sm-2.3.0.tar.gz#egg=en_core_web_sm==2.3.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (2.3.0)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from en_core_web_sm==2.3.0) (2.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.22.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (0.7.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (4.46.1)\n",
      "Requirement already satisfied: thinc==7.4.1 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (7.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.18.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.0.3)\n",
      "Requirement already satisfied: setuptools in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (41.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (3.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2020.6.20)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.0) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/mnefedov/.pyenv/versions/3.6.5/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "Collecting de_core_news_sm==2.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.3.0/de_core_news_sm-2.3.0.tar.gz (14.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 179 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from de_core_news_sm==2.3.0) (2.3.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (7.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.46.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.22.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.18.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.7.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.4.1)\n",
      "Requirement already satisfied: setuptools in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (41.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.23)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.1.0)\n",
      "Building wheels for collected packages: de-core-news-sm\n",
      "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.3.0-py3-none-any.whl size=14907581 sha256=8caeb2b9cc7b3677c895a68622fa05ccf82a9928018702842c7e5b0de32cdbf2\n",
      "  Stored in directory: /private/var/folders/sw/k25rhtrn2psc2hztd0t4tqmh0000gn/T/pip-ephem-wheel-cache-nd3kxcnr/wheels/fe/44/0f/7270b8ec13bc290e606a3c0f52f981915b1d09d1dfc7c79088\n",
      "Successfully built de-core-news-sm\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-2.3.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/Users/mnefedov/.pyenv/versions/3.6.5/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем пайплайн для английского языка\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = (\"One of the most salient features of our culture is that there is so much bullshit.” \"\n",
    "        \"These are the opening words of the short book On Bullshit, written by the philosopher Harry Frankfurt. \"\n",
    "        \"Fifteen years after the publication of this surprise bestseller, \"\n",
    "        \"the rapid progress of research on artificial intelligence is forcing us to reconsider our conception \"\n",
    "        \"of bullshit as a hallmark of human speech, with troubling implications. What do philosophical \"\n",
    "        \"reflections on bullshit have to do with algorithms? As it turns out, quite a lot.\"\n",
    "        \"In May this year the company OpenAI, co-founded by Elon Musk in 2015, introduced \"\n",
    "        \"a new language model called GPT-3 (for “Generative Pre-trained Transformer 3”). \"\n",
    "        \"It took the tech world by storm. On the surface, GPT-3 is like a supercharged version \"\n",
    "        \"of the autocomplete feature on your smartphone; it can generate coherent text based on \"\n",
    "        \"an initial input. But GPT-3’s text-generating abilities go far beyond anything your phone \"\n",
    "        \"is capable of. It can disambiguate pronouns, translate, infer, analogize, and even perform \"\n",
    "        \"some forms of common-sense reasoning and arithmetic. It can generate fake news articles \"\n",
    "        \"that humans can barely detect above chance. Given a definition, it can use a made-up word \"\n",
    "        \"in a sentence. It can rewrite a paragraph in the style of a famous author. Yes, it can \"\n",
    "        \"write creative fiction. Or generate code for a program based on a description of its \"\n",
    "        \"function. It can even answer queries about general knowledge. The list goes on.\"\n",
    "        \"WHO WROTE THIS?: Not long ago, hardly anyone suspected the hoax when this self-help \"\n",
    "        \"blog post, written by GPT-3, reached the top of Hacker News, a popular news aggregation \"\n",
    "        \"website. “You see, creative thinking is all about having fun,” GPT-3 writes. “If you spend\" \n",
    "        \"too much time on it, then it stops being fun and it just feels like work.”Substack\"\n",
    "        \"GPT-3 is a marvel of engineering due to its breathtaking scale. It contains \"\n",
    "        \"175 billion parameters (the weights in the connections between the “neurons”\" \n",
    "        \"or units of the network) distributed over 96 layers. It produces embeddings in a \"\n",
    "        \"vector space with 12,288 dimensions. And it was trained on hundreds of billions \"\n",
    "        \"of words representing a significant subset of the Internet—including the entirety \"\n",
    "        \"of English Wikipedia, countless books, and a dizzying number of web pages. Training \"\n",
    "        \"the final model alone is estimated to have cost around $5 million. By all accounts, \"\n",
    "        \"GPT-3 is a behemoth. Scaling up the size of its network and training data, without \"\n",
    "        \"fundamental improvements to the years-old architecture, was sufficient to bootstrap \"\n",
    "        \"the model into unexpectedly remarkable performance on a range of complex tasks, out \"\n",
    "        \"of the box. Indeed GPT-3 is capable of “few-shot,” and even, in some cases, “zero-shot,”\" \n",
    "        \"learning, or learning to perform a new task without being given any example of what success \"\n",
    "        \"looks like.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One one NUM\n",
      "of of ADP\n",
      "the the DET\n",
      "most most ADJ\n",
      "salient salient NOUN\n",
      "features feature NOUN\n",
      "of of ADP\n",
      "our -PRON- DET\n",
      "culture culture NOUN\n",
      "is be AUX\n",
      "that that SCONJ\n",
      "there there PRON\n",
      "is be AUX\n",
      "so so ADV\n",
      "much much ADJ\n",
      "bullshit bullshit NOUN\n",
      ". . PUNCT\n",
      "” \" PUNCT\n",
      "These these DET\n",
      "are be AUX\n",
      "the the DET\n",
      "opening open VERB\n",
      "words word NOUN\n",
      "of of ADP\n",
      "the the DET\n",
      "short short ADJ\n",
      "book book NOUN\n",
      "On on ADP\n",
      "Bullshit Bullshit PROPN\n",
      ", , PUNCT\n",
      "written write VERB\n",
      "by by ADP\n",
      "the the DET\n",
      "philosopher philosopher NOUN\n",
      "Harry Harry PROPN\n",
      "Frankfurt Frankfurt PROPN\n",
      ". . PUNCT\n",
      "Fifteen fifteen NUM\n",
      "years year NOUN\n",
      "after after ADP\n",
      "the the DET\n",
      "publication publication NOUN\n",
      "of of ADP\n",
      "this this DET\n",
      "surprise surprise NOUN\n",
      "bestseller bestseller NOUN\n",
      ", , PUNCT\n",
      "the the DET\n",
      "rapid rapid ADJ\n",
      "progress progress NOUN\n",
      "of of ADP\n",
      "research research NOUN\n",
      "on on ADP\n",
      "artificial artificial ADJ\n",
      "intelligence intelligence NOUN\n",
      "is be AUX\n",
      "forcing force VERB\n",
      "us -PRON- PRON\n",
      "to to PART\n",
      "reconsider reconsider VERB\n",
      "our -PRON- DET\n",
      "conception conception NOUN\n",
      "of of ADP\n",
      "bullshit bullshit NOUN\n",
      "as as SCONJ\n",
      "a a DET\n",
      "hallmark hallmark NOUN\n",
      "of of ADP\n",
      "human human ADJ\n",
      "speech speech NOUN\n",
      ", , PUNCT\n",
      "with with ADP\n",
      "troubling troubling ADJ\n",
      "implications implication NOUN\n",
      ". . PUNCT\n",
      "What what PRON\n",
      "do do AUX\n",
      "philosophical philosophical ADJ\n",
      "reflections reflection NOUN\n",
      "on on ADP\n",
      "bullshit bullshit PROPN\n",
      "have have AUX\n",
      "to to PART\n",
      "do do AUX\n",
      "with with ADP\n",
      "algorithms algorithm NOUN\n",
      "? ? PUNCT\n",
      "As as SCONJ\n",
      "it -PRON- PRON\n",
      "turns turn VERB\n",
      "out out ADP\n",
      ", , PUNCT\n",
      "quite quite DET\n",
      "a a DET\n",
      "lot lot NOUN\n",
      ". . PUNCT\n",
      "In in ADP\n",
      "May May PROPN\n",
      "this this DET\n",
      "year year NOUN\n",
      "the the DET\n",
      "company company NOUN\n",
      "OpenAI OpenAI PROPN\n",
      ", , PUNCT\n",
      "co co VERB\n",
      "- - VERB\n",
      "founded found VERB\n",
      "by by ADP\n",
      "Elon Elon PROPN\n",
      "Musk Musk PROPN\n",
      "in in ADP\n",
      "2015 2015 NUM\n",
      ", , PUNCT\n",
      "introduced introduce VERB\n",
      "a a DET\n",
      "new new ADJ\n",
      "language language NOUN\n",
      "model model NOUN\n",
      "called call VERB\n",
      "GPT-3 GPT-3 PROPN\n",
      "( ( PUNCT\n",
      "for for ADP\n",
      "“ \" PUNCT\n",
      "Generative Generative PROPN\n",
      "Pre Pre PROPN\n",
      "- - ADJ\n",
      "trained train VERB\n",
      "Transformer Transformer PROPN\n",
      "3 3 NUM\n",
      "” \" PUNCT\n",
      ") ) PUNCT\n",
      ". . PUNCT\n",
      "It -PRON- PRON\n",
      "took take VERB\n",
      "the the DET\n",
      "tech tech NOUN\n",
      "world world NOUN\n",
      "by by ADP\n",
      "storm storm NOUN\n",
      ". . PUNCT\n",
      "On on ADP\n",
      "the the DET\n",
      "surface surface NOUN\n",
      ", , PUNCT\n",
      "GPT-3 GPT-3 PROPN\n",
      "is be AUX\n",
      "like like SCONJ\n",
      "a a DET\n",
      "supercharged supercharged ADJ\n",
      "version version NOUN\n",
      "of of ADP\n",
      "the the DET\n",
      "autocomplete autocomplete PROPN\n",
      "feature feature NOUN\n",
      "on on ADP\n",
      "your -PRON- DET\n",
      "smartphone smartphone NOUN\n",
      "; ; PUNCT\n",
      "it -PRON- PRON\n",
      "can can VERB\n",
      "generate generate VERB\n",
      "coherent coherent ADJ\n",
      "text text NOUN\n",
      "based base VERB\n",
      "on on ADP\n",
      "an an DET\n",
      "initial initial ADJ\n",
      "input input NOUN\n",
      ". . PUNCT\n",
      "But but CCONJ\n",
      "GPT-3 GPT-3 PROPN\n",
      "’s ’s PART\n",
      "text text NOUN\n",
      "- - PUNCT\n",
      "generating generate VERB\n",
      "abilities ability NOUN\n",
      "go go VERB\n",
      "far far ADV\n",
      "beyond beyond ADP\n",
      "anything anything PRON\n",
      "your -PRON- DET\n",
      "phone phone NOUN\n",
      "is be AUX\n",
      "capable capable ADJ\n",
      "of of ADP\n",
      ". . PUNCT\n",
      "It -PRON- PRON\n",
      "can can VERB\n",
      "disambiguate disambiguate VERB\n",
      "pronouns pronoun NOUN\n",
      ", , PUNCT\n",
      "translate translate ADJ\n",
      ", , PUNCT\n",
      "infer infer ADJ\n",
      ", , PUNCT\n",
      "analogize analogize VERB\n",
      ", , PUNCT\n",
      "and and CCONJ\n",
      "even even ADV\n",
      "perform perform VERB\n",
      "some some DET\n",
      "forms form NOUN\n",
      "of of ADP\n",
      "common common ADJ\n",
      "- - PUNCT\n",
      "sense sense NOUN\n",
      "reasoning reasoning NOUN\n",
      "and and CCONJ\n",
      "arithmetic arithmetic ADJ\n",
      ". . PUNCT\n",
      "It -PRON- PRON\n",
      "can can VERB\n",
      "generate generate VERB\n",
      "fake fake ADJ\n",
      "news news NOUN\n",
      "articles article NOUN\n",
      "that that SCONJ\n",
      "humans human NOUN\n",
      "can can VERB\n",
      "barely barely ADV\n",
      "detect detect VERB\n",
      "above above ADP\n",
      "chance chance NOUN\n",
      ". . PUNCT\n",
      "Given give VERB\n",
      "a a DET\n",
      "definition definition NOUN\n",
      ", , PUNCT\n",
      "it -PRON- PRON\n",
      "can can VERB\n",
      "use use VERB\n",
      "a a DET\n",
      "made make VERB\n",
      "- - PUNCT\n",
      "up up ADP\n",
      "word word NOUN\n",
      "in in ADP\n",
      "a a DET\n",
      "sentence sentence NOUN\n",
      ". . PUNCT\n",
      "It -PRON- PRON\n",
      "can can VERB\n",
      "rewrite rewrite VERB\n",
      "a a DET\n",
      "paragraph paragraph NOUN\n",
      "in in ADP\n",
      "the the DET\n",
      "style style NOUN\n",
      "of of ADP\n",
      "a a DET\n",
      "famous famous ADJ\n",
      "author author NOUN\n",
      ". . PUNCT\n",
      "Yes yes INTJ\n",
      ", , PUNCT\n",
      "it -PRON- PRON\n",
      "can can VERB\n",
      "write write VERB\n",
      "creative creative ADJ\n",
      "fiction fiction NOUN\n",
      ". . PUNCT\n",
      "Or or CCONJ\n",
      "generate generate VERB\n",
      "code code NOUN\n",
      "for for ADP\n",
      "a a DET\n",
      "program program NOUN\n",
      "based base VERB\n",
      "on on ADP\n",
      "a a DET\n",
      "description description NOUN\n",
      "of of ADP\n",
      "its -PRON- DET\n",
      "function function NOUN\n",
      ". . PUNCT\n",
      "It -PRON- PRON\n",
      "can can VERB\n",
      "even even ADV\n",
      "answer answer VERB\n",
      "queries query NOUN\n",
      "about about ADP\n",
      "general general ADJ\n",
      "knowledge knowledge NOUN\n",
      ". . PUNCT\n",
      "The the DET\n",
      "list list NOUN\n",
      "goes go VERB\n",
      "on on ADP\n",
      ". . PUNCT\n",
      "WHO who PRON\n",
      "WROTE write VERB\n",
      "THIS this DET\n",
      "? ? PUNCT\n",
      ": : PUNCT\n",
      "Not not PART\n",
      "long long ADV\n",
      "ago ago ADV\n",
      ", , PUNCT\n",
      "hardly hardly ADV\n",
      "anyone anyone PRON\n",
      "suspected suspect VERB\n",
      "the the DET\n",
      "hoax hoax NOUN\n",
      "when when ADV\n",
      "this this DET\n",
      "self self NOUN\n",
      "- - PUNCT\n",
      "help help NOUN\n",
      "blog blog NOUN\n",
      "post post NOUN\n",
      ", , PUNCT\n",
      "written write VERB\n",
      "by by ADP\n",
      "GPT-3 GPT-3 PROPN\n",
      ", , PUNCT\n",
      "reached reach VERB\n",
      "the the DET\n",
      "top top NOUN\n",
      "of of ADP\n",
      "Hacker Hacker PROPN\n",
      "News News PROPN\n",
      ", , PUNCT\n",
      "a a DET\n",
      "popular popular ADJ\n",
      "news news NOUN\n",
      "aggregation aggregation NOUN\n",
      "website website NOUN\n",
      ". . PUNCT\n",
      "“ \" PUNCT\n",
      "You -PRON- PRON\n",
      "see see VERB\n",
      ", , PUNCT\n",
      "creative creative ADJ\n",
      "thinking thinking NOUN\n",
      "is be AUX\n",
      "all all ADV\n",
      "about about ADP\n",
      "having have VERB\n",
      "fun fun NOUN\n",
      ", , PUNCT\n",
      "” \" PUNCT\n",
      "GPT-3 GPT-3 PROPN\n",
      "writes write VERB\n",
      ". . PUNCT\n",
      "“ \" PUNCT\n",
      "If if SCONJ\n",
      "you -PRON- PRON\n",
      "spendtoo spendtoo VERB\n",
      "much much ADJ\n",
      "time time NOUN\n",
      "on on ADP\n",
      "it -PRON- PRON\n",
      ", , PUNCT\n",
      "then then ADV\n",
      "it -PRON- PRON\n",
      "stops stop VERB\n",
      "being be AUX\n",
      "fun fun ADJ\n",
      "and and CCONJ\n",
      "it -PRON- PRON\n",
      "just just ADV\n",
      "feels feel VERB\n",
      "like like SCONJ\n",
      "work work NOUN\n",
      ". . PUNCT\n",
      "”SubstackGPT-3 ”SubstackGPT-3 PROPN\n",
      "is be AUX\n",
      "a a DET\n",
      "marvel marvel NOUN\n",
      "of of ADP\n",
      "engineering engineering NOUN\n",
      "due due ADP\n",
      "to to ADP\n",
      "its -PRON- DET\n",
      "breathtaking breathtaking NOUN\n",
      "scale scale NOUN\n",
      ". . PUNCT\n",
      "It -PRON- PRON\n",
      "contains contain VERB\n",
      "175 175 NUM\n",
      "billion billion NUM\n",
      "parameters parameter NOUN\n",
      "( ( PUNCT\n",
      "the the DET\n",
      "weights weight NOUN\n",
      "in in ADP\n",
      "the the DET\n",
      "connections connection NOUN\n",
      "between between ADP\n",
      "the the DET\n",
      "“ \" PUNCT\n",
      "neurons”or neurons”or NUM\n",
      "units unit NOUN\n",
      "of of ADP\n",
      "the the DET\n",
      "network network NOUN\n",
      ") ) PUNCT\n",
      "distributed distribute VERB\n",
      "over over ADP\n",
      "96 96 NUM\n",
      "layers layer NOUN\n",
      ". . PUNCT\n",
      "It -PRON- PRON\n",
      "produces produce VERB\n",
      "embeddings embedding NOUN\n",
      "in in ADP\n",
      "a a DET\n",
      "vector vector NOUN\n",
      "space space NOUN\n",
      "with with ADP\n",
      "12,288 12,288 NUM\n",
      "dimensions dimension NOUN\n",
      ". . PUNCT\n",
      "And and CCONJ\n",
      "it -PRON- PRON\n",
      "was be AUX\n",
      "trained train VERB\n",
      "on on ADP\n",
      "hundreds hundred NOUN\n",
      "of of ADP\n",
      "billions billion NOUN\n",
      "of of ADP\n",
      "words word NOUN\n",
      "representing represent VERB\n",
      "a a DET\n",
      "significant significant ADJ\n",
      "subset subset NOUN\n",
      "of of ADP\n",
      "the the DET\n",
      "Internet internet NOUN\n",
      "— — PUNCT\n",
      "including include VERB\n",
      "the the DET\n",
      "entirety entirety NOUN\n",
      "of of ADP\n",
      "English English PROPN\n",
      "Wikipedia Wikipedia PROPN\n",
      ", , PUNCT\n",
      "countless countless ADJ\n",
      "books book NOUN\n",
      ", , PUNCT\n",
      "and and CCONJ\n",
      "a a DET\n",
      "dizzying dizzying ADJ\n",
      "number number NOUN\n",
      "of of ADP\n",
      "web web NOUN\n",
      "pages page NOUN\n",
      ". . PUNCT\n",
      "Training train VERB\n",
      "the the DET\n",
      "final final ADJ\n",
      "model model NOUN\n",
      "alone alone ADV\n",
      "is be AUX\n",
      "estimated estimate VERB\n",
      "to to PART\n",
      "have have AUX\n",
      "cost cost VERB\n",
      "around around ADP\n",
      "$ $ SYM\n",
      "5 5 NUM\n",
      "million million NUM\n",
      ". . PUNCT\n",
      "By by ADP\n",
      "all all DET\n",
      "accounts account NOUN\n",
      ", , PUNCT\n",
      "GPT-3 GPT-3 PROPN\n",
      "is be AUX\n",
      "a a DET\n",
      "behemoth behemoth NOUN\n",
      ". . PUNCT\n",
      "Scaling scale VERB\n",
      "up up ADP\n",
      "the the DET\n",
      "size size NOUN\n",
      "of of ADP\n",
      "its -PRON- DET\n",
      "network network NOUN\n",
      "and and CCONJ\n",
      "training training NOUN\n",
      "data datum NOUN\n",
      ", , PUNCT\n",
      "without without ADP\n",
      "fundamental fundamental ADJ\n",
      "improvements improvement NOUN\n",
      "to to ADP\n",
      "the the DET\n",
      "years year NOUN\n",
      "- - PUNCT\n",
      "old old ADJ\n",
      "architecture architecture NOUN\n",
      ", , PUNCT\n",
      "was be AUX\n",
      "sufficient sufficient ADJ\n",
      "to to PART\n",
      "bootstrap bootstrap VERB\n",
      "the the DET\n",
      "model model NOUN\n",
      "into into ADP\n",
      "unexpectedly unexpectedly ADV\n",
      "remarkable remarkable ADJ\n",
      "performance performance NOUN\n",
      "on on ADP\n",
      "a a DET\n",
      "range range NOUN\n",
      "of of ADP\n",
      "complex complex ADJ\n",
      "tasks task NOUN\n",
      ", , PUNCT\n",
      "out out SCONJ\n",
      "of of ADP\n",
      "the the DET\n",
      "box box NOUN\n",
      ". . PUNCT\n",
      "Indeed indeed ADV\n",
      "GPT-3 GPT-3 PROPN\n",
      "is be AUX\n",
      "capable capable ADJ\n",
      "of of ADP\n",
      "“ \" PUNCT\n",
      "few few ADJ\n",
      "- - PUNCT\n",
      "shot shot NOUN\n",
      ", , PUNCT\n",
      "” \" PUNCT\n",
      "and and CCONJ\n",
      "even even ADV\n",
      ", , PUNCT\n",
      "in in ADP\n",
      "some some DET\n",
      "cases case NOUN\n",
      ", , PUNCT\n",
      "“ \" PUNCT\n",
      "zero zero NUM\n",
      "- - PUNCT\n",
      "shot,”learning shot,”learning PART\n",
      ", , PUNCT\n",
      "or or CCONJ\n",
      "learning learn VERB\n",
      "to to PART\n",
      "perform perform VERB\n",
      "a a DET\n",
      "new new ADJ\n",
      "task task NOUN\n",
      "without without ADP\n",
      "being be AUX\n",
      "given give VERB\n",
      "any any DET\n",
      "example example NOUN\n",
      "of of ADP\n",
      "what what DET\n",
      "success success NOUN\n",
      "looks look VERB\n",
      "like like SCONJ\n",
      ". . PUNCT\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents: # достаем предложения\n",
    "    for token in sent: # достаем токены\n",
    "        print(token.text, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: ['the most salient features', 'our culture', 'so much bullshit', 'the opening words', 'the short book', 'Bullshit', 'the philosopher', 'Harry Frankfurt', 'the publication', 'this surprise bestseller', 'the rapid progress', 'research', 'artificial intelligence', 'us', 'our conception', 'bullshit', 'a hallmark', 'human speech', 'troubling implications', 'What', 'philosophical reflections', 'bullshit', 'algorithms', 'it', 'May', 'the company', 'co-founded by Elon Musk', 'a new language model', 'Generative', 'Pre-trained Transformer', 'It', 'the tech world', 'storm', 'the surface', 'GPT-3', 'a supercharged version', 'the autocomplete feature', 'your smartphone', 'it', 'coherent text', 'an initial input', 'GPT-3’s text-generating abilities', 'anything', 'your phone', 'It', 'pronouns', 'some forms', 'common-sense reasoning', 'It', 'fake news articles', 'humans', 'chance', 'a definition', 'it', 'a made-up word', 'a sentence', 'It', 'a paragraph', 'the style', 'a famous author', 'it', 'creative fiction', 'code', 'a program', 'a description', 'its function', 'It', 'queries', 'general knowledge', 'The list', 'WHO', 'anyone', 'the hoax', 'this self-help blog post', 'GPT-3', 'the top', 'Hacker News', 'a popular news aggregation website', 'You', 'creative thinking', 'fun', 'GPT-3', 'you', 'much time', 'it', 'it', 'it', 'work', '”SubstackGPT-3', 'a marvel', 'engineering', 'its breathtaking scale', 'It', '175 billion parameters', 'the weights', 'the connections', 'the “neurons”or units', 'the network', '96 layers', 'It', 'embeddings', 'a vector space', '12,288 dimensions', 'it', 'hundreds', 'billions', 'words', 'a significant subset', 'the Internet', 'the entirety', 'English Wikipedia', 'countless books', 'a dizzying number', 'web pages', 'the final model', 'all accounts', 'GPT-3', 'a behemoth', 'the size', 'its network and training data', 'fundamental improvements', 'the years-old architecture', 'the model', 'unexpectedly remarkable performance', 'a range', 'complex tasks', 'the box', 'GPT-3', '“few-shot', 'some cases', 'a new task', 'any example', 'success']\n"
     ]
    }
   ],
   "source": [
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем пайплайн для немецкого языка\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = (\"Vor den Stadien habe ich bis jetzt zum Glück noch keine wüsten Szenen gesehen.\"\n",
    "        \"Vorstandschef Timotheus Höttges habe sich ausgesprochen optimistisch gezeigt, schrieb Analyst Robert Grindle in einer Studie vom Montag. \"\n",
    "        \"Während der dortigen Räterepublik war er nach dem Krieg in Künstlergruppen und Ausschüssen aktiv.\"\n",
    "        \"Welches Ergebnis die Diskussion auf EU-Ebene auch letztlich bringt, wichtig ist, dass die Preisentwicklung für die\"\n",
    "        \"Menschen verträglicher gestaltet wird“, so Gusenbauer.\"\n",
    "        \"Weitere Informationen unter www.schnippenburg.de sowie www.eisenzeithaus.de. Es gibt neue Nachrichten auf noz.de!\" \n",
    "        \"Jetzt die Startseite neu laden.\"\n",
    "        \"Der Initiative 'Zivilcourage', die sich jahrelang für das Denkmal in Form eines offenen \" \n",
    "        \"Der islamistischen Szene Thüringens wurden nach Angaben des Thüringer Innenministeriums \"\n",
    "        \"zuletzt etwa 125 Personen zugerechnet, der salafistischen Szene etwa 75 Personen.\"\n",
    "        \"Allerdings bestand er die EMV-Prüfung nicht, weil er Radios und DVB-T-Empfänger stört.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vor Vor ADP\n",
      "den der DET\n",
      "Stadien Stadium NOUN\n",
      "habe habe AUX\n",
      "ich ich PRON\n",
      "bis bis ADP\n",
      "jetzt jetzt ADV\n",
      "zum zum ADP\n",
      "Glück Glück NOUN\n",
      "noch noch ADV\n",
      "keine kein DET\n",
      "wüsten wüst ADJ\n",
      "Szenen Szene NOUN\n",
      "gesehen sehen VERB\n",
      ". . PUNCT\n",
      "Vorstandschef Vorstandschef NOUN\n",
      "Timotheus Timotheus PROPN\n",
      "Höttges Höttges PROPN\n",
      "habe habe AUX\n",
      "sich sich PRON\n",
      "ausgesprochen aussprechen ADJ\n",
      "optimistisch optimistisch ADJ\n",
      "gezeigt zeigen VERB\n",
      ", , PUNCT\n",
      "schrieb schreiben VERB\n",
      "Analyst Analyst NOUN\n",
      "Robert Robert PROPN\n",
      "Grindle Grindle PROPN\n",
      "in in ADP\n",
      "einer einer DET\n",
      "Studie Studie NOUN\n",
      "vom vom ADP\n",
      "Montag Montag NOUN\n",
      ". . PUNCT\n",
      "Während während SCONJ\n",
      "der der DET\n",
      "dortigen dortig ADJ\n",
      "Räterepublik Räterepublik NOUN\n",
      "war sein AUX\n",
      "er ich PRON\n",
      "nach nach ADP\n",
      "dem der DET\n",
      "Krieg Krieg NOUN\n",
      "in in ADP\n",
      "Künstlergruppen Künstlergruppen NOUN\n",
      "und und CCONJ\n",
      "Ausschüssen Ausschuß NOUN\n",
      "aktiv aktiv ADJ\n",
      ". . PUNCT\n",
      "Welches welch DET\n",
      "Ergebnis Ergebnis NOUN\n",
      "die der DET\n",
      "Diskussion Diskussion NOUN\n",
      "auf auf ADP\n",
      "EU-Ebene EU-Ebene NOUN\n",
      "auch auch ADV\n",
      "letztlich letztlich ADV\n",
      "bringt bringen VERB\n",
      ", , PUNCT\n",
      "wichtig wichtig ADJ\n",
      "ist sein AUX\n",
      ", , PUNCT\n",
      "dass dass SCONJ\n",
      "die der DET\n",
      "Preisentwicklung Preisentwicklung NOUN\n",
      "für für ADP\n",
      "dieMenschen dieMenschen NOUN\n",
      "verträglicher verträglich ADJ\n",
      "gestaltet gestalten VERB\n",
      "wird werden AUX\n",
      "“ “ PUNCT\n",
      ", , PUNCT\n",
      "so so ADV\n",
      "Gusenbauer Gusenbauer PROPN\n",
      ". . PUNCT\n",
      "Weitere Weitere ADJ\n",
      "Informationen Information NOUN\n",
      "unter unter ADP\n",
      "www.schnippenburg.de www.schnippenburg.de NOUN\n",
      "sowie sowie CCONJ\n",
      "www.eisenzeithaus.de www.eisenzeithaus.de NOUN\n",
      ". . PUNCT\n",
      "Es ich PRON\n",
      "gibt geben VERB\n",
      "neue neue ADJ\n",
      "Nachrichten Nachricht NOUN\n",
      "auf auf ADP\n",
      "noz.de noz.de NOUN\n",
      "! ! PUNCT\n",
      "Jetzt Jetzt ADV\n",
      "die der DET\n",
      "Startseite Startseite NOUN\n",
      "neu neu ADJ\n",
      "laden laden VERB\n",
      ". . PUNCT\n",
      "Der der DET\n",
      "Initiative Initiative NOUN\n",
      "' ' PUNCT\n",
      "Zivilcourage Zivilcourage PROPN\n",
      "' ' PUNCT\n",
      ", , PUNCT\n",
      "die der PRON\n",
      "sich sich PRON\n",
      "jahrelang jahrelang ADJ\n",
      "für für ADP\n",
      "das der DET\n",
      "Denkmal Denkmal NOUN\n",
      "in in ADP\n",
      "Form Form NOUN\n",
      "eines ein DET\n",
      "offenen offen ADJ\n",
      "Der der DET\n",
      "islamistischen islamistischen ADJ\n",
      "Szene Szene NOUN\n",
      "Thüringens Thüringen PROPN\n",
      "wurden werden AUX\n",
      "nach nach ADP\n",
      "Angaben Angabe NOUN\n",
      "des der DET\n",
      "Thüringer Thüringer ADJ\n",
      "Innenministeriums Innenministerium NOUN\n",
      "zuletzt zuletzt ADV\n",
      "etwa etwa ADV\n",
      "125 125 NUM\n",
      "Personen Person NOUN\n",
      "zugerechnet zurechnen VERB\n",
      ", , PUNCT\n",
      "der der DET\n",
      "salafistischen salafistischen ADJ\n",
      "Szene Szene NOUN\n",
      "etwa etwa ADV\n",
      "75 75 NUM\n",
      "Personen Person NOUN\n",
      ". . PUNCT\n",
      "Allerdings Allerdings ADV\n",
      "bestand bestand VERB\n",
      "er ich PRON\n",
      "die der DET\n",
      "EMV-Prüfung EMV-Prüfung NOUN\n",
      "nicht nicht PART\n",
      ", , PUNCT\n",
      "weil weil SCONJ\n",
      "er ich PRON\n",
      "Radios Radio NOUN\n",
      "und und CCONJ\n",
      "DVB-T-Empfänger DVB-T-Empfänger NOUN\n",
      "stört stören VERB\n",
      ". . PUNCT\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents: # достаем предложения\n",
    "    for token in sent: # достаем токены\n",
    "        print(token.text, token.lemma_, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: ['den Stadien', 'ich', 'Glück', 'noch keine wüsten Szenen', 'Vorstandschef Timotheus Höttges', 'sich', 'Analyst Robert Grindle', 'einer Studie', 'Montag', 'der dortigen Räterepublik', 'er', 'dem Krieg', 'Künstlergruppen', 'Ausschüssen', 'Welches Ergebnis', 'die Diskussion', 'EU-Ebene', 'die Preisentwicklung', 'dieMenschen', 'Welches Ergebnis die Diskussion auf EU-Ebene auch letztlich bringt, wichtig ist, dass die Preisentwicklung für dieMenschen verträglicher gestaltet wird“, so Gusenbauer', 'Weitere Informationen', 'www.schnippenburg.de', 'www.eisenzeithaus.de', 'neue Nachrichten', 'noz.de', 'die Startseite', \"Der Initiative 'Zivilcourage\", 'die', 'sich', 'das Denkmal', 'Form', 'eines offenen Der islamistischen Szene', 'Thüringens', 'Angaben', 'des Thüringer Innenministeriums', 'etwa 125 Personen', 'der salafistischen Szene', 'etwa 75 Personen', 'er', 'die EMV-Prüfung', 'er', 'Radios', 'DVB-T-Empfänger']\n"
     ]
    }
   ],
   "source": [
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть русскоязычный форк spacy - https://github.com/buriy/spacy-ru Но это конечно не полноценный spacy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
