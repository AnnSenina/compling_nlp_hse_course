{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 17 not upgraded.\n",
      "Need to get 167 kB of archives.\n",
      "After this operation, 558 kB of additional disk space will be used.\n",
      "Get:1 http://mirror.yandex.ru/ubuntu bionic/main amd64 unzip amd64 6.0-21ubuntu1 [167 kB]\n",
      "Fetched 167 kB in 0s (1049 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package unzip.\n",
      "(Reading database ... 6778 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-21ubuntu1_amd64.deb ...\n",
      "Unpacking unzip (6.0-21ubuntu1) ...\n",
      "Setting up unzip (6.0-21ubuntu1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  quora.csv.zip\n",
      "  inflating: quora.csv               \n",
      "  inflating: __MACOSX/._quora.csv    \n"
     ]
    }
   ],
   "source": [
    "!unzip quora.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (2.10.0)\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.0.3-cp37-cp37m-manylinux1_x86_64.whl (10.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.0 MB 670 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tokenizers==0.7.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2020.5.14)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (0.15.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.0.0)\n",
      "Installing collected packages: pandas\n",
      "Successfully installed pandas-1.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sklearn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# стандартные библиотеки\n",
    "import os, re\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# pytortch и huggingface \n",
    "import torch\n",
    "from transformers.modeling_auto import AutoModel\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем данные с соревнования по определению токсичных вопросов на Quora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('quora.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('qid', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text  target\n",
       "0  How did Quebec nationalists see their province...       0\n",
       "1  Do you have an adopted dog, how would you enco...       0\n",
       "2  Why does velocity affect time? Does velocity a...       0\n",
       "3  How did Otto von Guericke used the Magdeburg h...       0\n",
       "4  Can I convert montra helicon D to a mountain b...       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные на трейн и тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.05, stratify=data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240815, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65307, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем предобученную модель из huggingface transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список всех доступных моделей можно найти тут - https://huggingface.co/models  \n",
    "А вот тут основные с описанием - https://huggingface.co/transformers/pretrained_models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные у нас на английском, поэтому мы возьмем оригинального Берта (остальные модели загружаются также)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Eng Bert\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "model_bert = AutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rubert - от IPavlov\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "# model_bert = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased\").to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Multilingual Bert - от гугла\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "# model_bert = AutoModel.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы загружаем не только модель, а еще и токенайзер, т.е. свою предобработку нам писать не нужно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How did Quebec nationalists see their province as a nation in the 1960s?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[0, 'question_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перевести токены в индексы очень просто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 1731,\n",
       " 1225,\n",
       " 5181,\n",
       " 25170,\n",
       " 1267,\n",
       " 1147,\n",
       " 3199,\n",
       " 1112,\n",
       " 170,\n",
       " 3790,\n",
       " 1107,\n",
       " 1103,\n",
       " 3266,\n",
       " 136,\n",
       " 102]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('How did Quebec nationalists see their province as a nation in the 1960s?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этих моделях как правило используется BPE, но на стандартных словах этого не видно и может показаться, что все просто разбивается по пробелам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'How',\n",
       " 'did',\n",
       " 'Quebec',\n",
       " 'nationalists',\n",
       " 'see',\n",
       " 'their',\n",
       " 'province',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nation',\n",
       " 'in',\n",
       " 'the',\n",
       " '1960s',\n",
       " '?',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# переводим индекс токена обратно в текст\n",
    "encoded = tokenizer.encode('How did Quebec nationalists see their province as a nation in the 1960s?')\n",
    "[tokenizer.decode([x]) for x in encoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем опечатки словах, чтобы увидеть, что это все-таки BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'H',\n",
       " '##w',\n",
       " 'did',\n",
       " 'Q',\n",
       " '##ube',\n",
       " '##c',\n",
       " 'na',\n",
       " '##zio',\n",
       " '##nal',\n",
       " '##ists',\n",
       " 'see',\n",
       " 'their',\n",
       " 'province',\n",
       " 'as',\n",
       " '##a',\n",
       " 'nation',\n",
       " 'in',\n",
       " 'the',\n",
       " '1960s',\n",
       " '?',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# переводим индекс токена обратно в текст\n",
    "encoded = tokenizer.encode('Hw did Qubec nazionalists see their province asa nation in the 1960s?')\n",
    "[tokenizer.decode([x]) for x in encoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индексы можно напрямую передавать в модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'How did Quebec nationalists see their province as a nation in the 1960s?'\n",
    "\n",
    "text_ids = torch.tensor([tokenizer.encode(text, add_special_tokens=True)])\n",
    "\n",
    "output = model_bert(text_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выходе мы получим tuple из двух элементов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый элемент - состояния енкодера для каждого из элементов последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].size() # в пайторче вместо .shape используется size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй - состояние енкодера на первом элементе, пропущенное через активацию (обычно этот элемент не используют)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно в задачах используют либо состояние первого элемента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][:,0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Либо усредненное состояние "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(output[0], axis=1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные эмбеддинги уже можно использовать для какой-нибудь кластеризации или поиска похожих. А если есть разметка, то можно обучить на этих векторах стандартную модель из sklearn или даже дообучить всего Берта под конкретную задачу!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем дообучить (fine-tune) модель на данных Quora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно прописать генератор бачтей и саму модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches_train(train, batch_size=32):\n",
    "    # очень простая функция\n",
    "    # перемешиваем датасет и выдает тексты и метки классов по кусочкам (в 32 например)\n",
    "    batch_q = []\n",
    "    batch_a = []\n",
    "    \n",
    "    while True: # чтобы сам никогда не заканчивался\n",
    "        \n",
    "        for i, (q,a) in enumerate(train.sample(frac=1.).values):\n",
    "            \n",
    "            batch_q.append(q)\n",
    "            batch_a.append(a)\n",
    "\n",
    "            if len(batch_q) == batch_size:\n",
    "\n",
    "                yield (batch_q,\n",
    "                       np.array(batch_a, dtype=np.int32))\n",
    "                batch_q = []\n",
    "                batch_a = []\n",
    "\n",
    "                \n",
    "def generate_batches_test(test, batch_size=32):\n",
    "    # тоже самое только без бесконечной генерации\n",
    "    batch_q = []\n",
    "    batch_a = []\n",
    "        \n",
    "    for i, (q,a) in enumerate(test.values):\n",
    "\n",
    "        batch_q.append(q)\n",
    "        batch_a.append(a)\n",
    "\n",
    "        if len(batch_q) == batch_size:\n",
    "\n",
    "            yield (batch_q,\n",
    "                   np.array(batch_a, dtype=np.int32))\n",
    "            batch_q = []\n",
    "            batch_a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generate_batches_train(train, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Is it possible to get a poultry job in Canada from Nigeria?',\n",
       "  'What did the Brazilian Defenders do and not get red cards to James Rodriguez that made him weep?',\n",
       "  'Are the apolipoproteins in a lipoprotein hydrophobic or amphipathic?',\n",
       "  'Why is London a Heaven for loan defaulters of India?',\n",
       "  'What policies Mexico has adopted to resettle and reintegrate displaced population through improving food security?',\n",
       "  'Why do people smile while taking photograghs?',\n",
       "  'How do I convert 14 v AC supply into DC?',\n",
       "  'Is Rugby union dangerous, and if so, can it be made safer?'],\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь модель. До этого мы не использовали pytorch, но не пугайтесь. У нас не такая сложная модель и различия все-таки не такие большие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CLF(nn.Module):\n",
    "    \n",
    "    def __init__(self, pretrained_model):\n",
    "        super().__init__()          \n",
    "        # этот шаг похож на определение модели в керасе через Functional API\n",
    "        self.tokenizer = tokenizer # токенизатор\n",
    "        self.pretrained_model = pretrained_model # предобученная модель\n",
    "\n",
    "        self.fc = nn.Linear(768, 1) # аналог Dense слоя без активации (но нужно указать shape - 768 на вход 1 на выход)\n",
    "        self.act = nn.Sigmoid() # активация\n",
    "        \n",
    "    # тут задает как слои будут применятся к входным данным\n",
    "    def forward(self, texts):\n",
    "        # токенизируем\n",
    "        texts_ids = [torch.tensor(self.tokenizer.encode(t, add_special_tokens=True)) for t in texts]\n",
    "        # делаем паддинг\n",
    "        texts_ids = torch.nn.utils.rnn.pad_sequence(texts_ids, batch_first=True, \n",
    "                                                    padding_value=self.tokenizer.pad_token_id).to(torch.device('cuda'))\n",
    "        # чтобы нули не учитывались считаем маску\n",
    "        mask = (texts_ids != tokenizer.pad_token_id).long()\n",
    "        \n",
    "        # прогоняем через BERT\n",
    "        hidden = self.pretrained_model(texts_ids, attention_mask=mask)[0]\n",
    "\n",
    "        # берем самое первое состояние и применяем к нему линейный слой и активацию\n",
    "        dense_outputs=self.fc(hidden[:,0] )\n",
    "        outputs=self.act(dense_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем оптимизатор, лосс и метрику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLF(model_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5) # тот же адам\n",
    "criterion = nn.BCELoss() # binary_crossentropy\n",
    "\n",
    "#обычная accuracy\n",
    "def accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(preds)\n",
    "    \n",
    "    correct = (rounded_preds == y).float() \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель готова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В торче больше вещей нужно делать вручную. Например, нужно посылать модель или тензоры на видеокарту. Поэтому к модели добавится .to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучающий цикл тоже надо прописывать подробнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = generate_batches_train(train, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24015134515240788 0.9100000078231096\n",
      "0.19485027224291115 0.9270000076666475\n",
      "0.17506930229254067 0.935166672890385\n",
      "0.16318675937596708 0.9391250059194863\n",
      "0.153706934761256 0.9407000060230494\n",
      "0.14777731076154546 0.9422500057145953\n",
      "0.1425283735388491 0.9440000051366432\n",
      "0.14049461299582616 0.9445625052694231\n",
      "0.13800016964759884 0.946277782726619\n",
      "0.1362622226185631 0.9468000043705106\n",
      "0.13417358377884905 0.9475000043958426\n",
      "0.1334997557090052 0.9481250042282044\n",
      "0.132444141268766 0.9485769270990904\n",
      "0.13194980433110945 0.9483214326468962\n",
      "0.13167523896383743 0.9483666707724333\n",
      "0.13096283352177124 0.9484062540577725\n",
      "0.13120313635356176 0.948264710066073\n",
      "0.12941021727307492 0.9489444486010405\n",
      "0.12803378262814427 0.9495789514129099\n",
      "0.12734245934465435 0.9496500040329993\n",
      "0.1265202674105586 0.9497380992663759\n",
      "0.12652335708939724 0.9498181858963587\n",
      "0.12582117192467432 0.9501739170531863\n",
      "0.12521345609071433 0.9503125039767474\n",
      "0.12455962450830266 0.9504800039798021\n",
      "0.12385731470636809 0.9508269269449207\n",
      "0.12307790628849977 0.9510000037512294\n",
      "0.1225142785706391 0.9512142894550094\n",
      "0.12155960678556485 0.9514655208613338\n",
      "0.12091249892212606 0.951816670221587\n",
      "0.1205543961496498 0.9520483905485561\n",
      "0.12056204363721917 0.9520000034407713\n",
      "0.11995073184215774 0.9521515186289043\n",
      "0.11917195359416141 0.9523235328254455\n",
      "0.11862685476842204 0.9526285747651543\n",
      "0.11788806481752545 0.9529027810547914\n",
      "0.11799565359245281 0.9529324357110907\n",
      "0.11799849192440313 0.9529078980672516\n",
      "0.11716681885813626 0.9533333365752911\n",
      "0.11654726221453166 0.9537375032473355\n",
      "0.11612180939688142 0.9539878080839791\n",
      "0.1160115977274143 0.954023812741396\n",
      "0.11560584219069718 0.9542093055071525\n",
      "0.11542699640673659 0.9543409122272649\n",
      "0.11502094764556063 0.9545444475296471\n",
      "0.11478739851907291 0.9546521769804152\n",
      "0.11473455015553825 0.9546595774955572\n",
      "0.11475914706285645 0.9546979196881875\n",
      "0.11455460388435536 0.9547959214099208\n",
      "0.11431780032966053 0.95489000300318\n",
      "0.11397822612950204 0.9549411794616312\n",
      "0.1138952245598529 0.9550000029472777\n",
      "0.11408395949728076 0.9549528331590711\n",
      "0.11404271718980184 0.9549722251309841\n",
      "0.11378468997263222 0.9550818210637028\n",
      "0.11368705812603626 0.9551250028517098\n",
      "0.11353060929941038 0.9551842133530922\n",
      "0.1135160203756873 0.9551293131619178\n",
      "0.11313924178665591 0.9552796637923535\n",
      "0.11270315704020323 0.9554250027748445\n",
      "0.11238910148094874 0.9555000027684403\n",
      "0.11237745470081027 0.9554838737088346\n",
      "0.11228307472411654 0.9555952407833602\n",
      "0.11222494286342226 0.9556171901815105\n",
      "0.11223817243909714 0.9557000026622644\n",
      "0.1121446131518601 0.9557121238846219\n",
      "0.11216571364484887 0.9557686593917324\n",
      "0.11221252626878969 0.9557279438580222\n",
      "0.11219803464658848 0.9557029012331496\n",
      "0.11205986011394999 0.9557714312172362\n",
      "0.11181387732875317 0.9558521153232161\n",
      "0.11177388457737429 0.9558333359834634\n",
      "0.11160779611792014 0.9558904136135562\n",
      "0.11143347762327648 0.9558986513044786\n",
      "0.11113813573290439 0.9560200026442607\n",
      "0.11111946462236168 0.9560526342072377\n",
      "0.11106832684803143 0.9560194831709196\n",
      "0.1110630344140018 0.9560256436782387\n",
      "0.11099224575655976 0.9560253191079142\n",
      "0.1106941690326712 0.9561312526399269\n",
      "0.11057498043120614 0.9561728421488294\n",
      "0.11045416970191405 0.9562195148200887\n",
      "0.11032680072941599 0.956331327903163\n",
      "0.11034140503501735 0.9563095264429493\n",
      "0.11033323823933845 0.9562588261935641\n",
      "0.11007238018057759 0.9562965142874177\n",
      "0.11007113820016143 0.9562931061005113\n",
      "0.10986980665048494 0.9563409117346798\n",
      "0.1096961463165268 0.9564382048612565\n",
      "0.10949188472829216 0.9565166692742043\n",
      "0.10939233723031945 0.9565384641265149\n",
      "0.10933868727542374 0.9565000026000906\n",
      "0.10919100692255988 0.956537636987144\n",
      "0.10902399057758343 0.9566276621319195\n",
      "0.10899548547173923 0.956652634125791\n",
      "0.10898037968550853 0.9566614608536474\n",
      "0.10894268028923555 0.9566804148433442\n",
      "0.10890707846392987 0.9566938800235488\n",
      "0.10883440568224137 0.9567777802433931\n",
      "0.10882991360299639 0.9567700024552643\n",
      "0.10881139565876449 0.9567722797047089\n",
      "0.10888397251200456 0.9567156887529236\n",
      "0.10887365830446778 0.956791264565969\n",
      "0.10878745423208434 0.9567788486132541\n",
      "0.1087557636920662 0.9567904786446265\n",
      "0.10869542599909934 0.9568018892526908\n",
      "0.10862718205989848 0.9568271052454398\n",
      "0.10861378034071768 0.9568240764964786\n",
      "0.10848961253632863 0.9568578005828169\n",
      "0.10830639587795171 0.9569272751381451\n",
      "0.10830017668196643 0.9569774798827397\n",
      "0.10815939172255769 0.9570535738240661\n",
      "0.10818778532373294 0.9570530997447472\n",
      "0.10805777978635568 0.9570789497679001\n",
      "0.10800304958019305 0.9571000024138585\n",
      "0.10799442560768763 0.9571206920728859\n",
      "0.10797836413366708 0.9570940195145006\n",
      "0.10790665939511924 0.9571271210713154\n",
      "0.10786433959789202 0.9571386578760478\n",
      "0.10770475496212506 0.9571791690693547\n",
      "0.10773098343583536 0.9571900850491336\n",
      "0.10767801883453446 0.9571803302507176\n",
      "0.10756201043222914 0.9572195145663449\n",
      "0.10741523624335382 0.9572459700998039\n",
      "0.10739559909415897 0.9572560023552179\n",
      "0.10730019878275926 0.9573015896627117\n",
      "0.1072972145010708 0.957271655897104\n",
      "0.10728429492620763 0.9572382836049655\n",
      "0.1071136937719407 0.9572751961480971\n",
      "0.10698082060914468 0.9573307715751804\n",
      "0.10696919543778378 0.9573740481289515\n",
      "0.1069080303519458 0.9574090932270117\n",
      "0.10688623817368408 0.9574097767410645\n",
      "0.10684508864757859 0.9574029873828612\n",
      "0.10675828815070067 0.9574777800777444\n",
      "0.10673738876006289 0.9574852964287515\n",
      "0.1065687648390622 0.9575146008326407\n",
      "0.10644196699295393 0.9575579732877837\n",
      "0.10628058980532717 0.9576007217045525\n",
      "0.10613429644656051 0.9576464308505612\n",
      "0.10608403501121066 0.9576985838359341\n",
      "0.1060816374858292 0.9576971853708087\n",
      "0.1060059871686292 0.957716785490617\n",
      "0.10593545084523713 0.9577083356062778\n",
      "0.10582009808628033 0.9577275884814304\n",
      "0.10571023502227235 0.9577842488318478\n",
      "0.10559513315784533 0.957819730137177\n",
      "0.10554007772810528 0.957841218460754\n",
      "0.10560773911468306 0.9578087271024917\n",
      "0.10550636545164743 0.9578666689281662\n",
      "0.10550672731246254 0.9578443731106078\n",
      "0.10539419062024727 0.9578717127839398\n",
      "0.10532810912959832 0.9579150349296192\n",
      "0.1053064290695603 0.9579123399130903\n",
      "0.10531018796976986 0.957903228048836\n",
      "0.10525582596727569 0.9579358996837758\n",
      "0.10515028540214826 0.9579777092391708\n",
      "0.10513417762436733 0.9579873439900671\n",
      "0.10514940701542955 0.9580031468550552\n",
      "0.10510538020407693 0.9580250022006221\n",
      "0.10505963286362525 0.9580279525175043\n",
      "0.10508273542001355 0.958021607145575\n",
      "0.10508147654982793 0.9580490819703034\n",
      "0.1049882940327814 0.9580945144089439\n",
      "0.1048789599132089 0.9581606082523411\n",
      "0.1047606639295651 0.9581777130341135\n",
      "0.10478395070197495 0.9581796429047506\n",
      "0.10474963969667442 0.9581845259990188\n",
      "0.10474562813139372 0.9582011856204835\n",
      "0.10476176930868121 0.9581588257134838\n",
      "0.10474777218187228 0.9581315811409762\n",
      "0.10467498364896231 0.9581395370881398\n",
      "0.10467606245063654 0.9581416207039459\n",
      "0.10466477545868103 0.958123565419395\n",
      "0.10465468145322188 0.958102859340821\n",
      "0.10471374027049354 0.9580454567485405\n",
      "0.1046003375642099 0.9580875728195165\n",
      "0.10456304211141358 0.9580702269248915\n",
      "0.10455866578091638 0.9580586614160065\n",
      "0.1044745903986946 0.9580750021938649\n",
      "0.10450412546995852 0.9580635381144219\n",
      "0.10445871002237814 0.9580796725380716\n",
      "0.10442102023016132 0.9580956306422506\n",
      "0.10439304326712812 0.9581032630934826\n",
      "0.10433562475125104 0.9581189211417694\n",
      "0.10437359975244705 0.9581102172697904\n",
      "0.10428956600316341 0.9581443872366519\n",
      "0.10427561437743939 0.9581383000888881\n",
      "0.10423268047011723 0.9581613778756567\n",
      "0.10410953957129784 0.9582236864131533\n",
      "0.10399916729160233 0.9582696357045655\n",
      "0.10400420275152404 0.9582734396902378\n",
      "0.10403029315636271 0.9582616602266545\n",
      "0.10393906140244523 0.958314435184386\n",
      "0.10382851386812922 0.9583820534520424\n",
      "0.103791431965228 0.9583979613596232\n",
      "0.10376299516574437 0.9584340123177936\n",
      "0.10374427183077323 0.9584292950959067\n",
      "0.10369370768308855 0.9584321629615435\n",
      "0.10362502262503841 0.9584475021574647\n",
      "0.10360606019068927 0.9584253752887694\n",
      "0.10357003002206214 0.9584554476906905\n",
      "0.10354209811704834 0.95843349968308\n",
      "0.10346675509710193 0.9584681393969439\n",
      "0.10346615331928904 0.958456099690824\n",
      "0.10343561715397812 0.9584563128060652\n",
      "0.10334575215491786 0.9584879248301332\n",
      "0.1032541254057343 0.9585168290428387\n",
      "0.10316649250559727 0.9585526336897076\n",
      "0.10311372336651575 0.958576192580873\n",
      "0.10313317646276894 0.9585616134838046\n",
      "0.1030359820291545 0.9586344360549636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10298817169930165 0.958652584250894\n",
      "0.10297050414939855 0.9586495348034757\n",
      "0.10293950775664214 0.9586511648813653\n",
      "0.10284701997789347 0.9587106502280329\n",
      "0.10277028941899143 0.9587396334067055\n",
      "0.10270885672019218 0.9587614699518052\n",
      "0.10263934344788439 0.958778540876154\n",
      "0.10262966550615171 0.9587704566070302\n",
      "0.10258122054822595 0.9588009070301622\n",
      "0.10259138114684836 0.9588018038496375\n",
      "0.10257205227574212 0.9588183876942226\n",
      "0.1025493865831491 0.9588258949005312\n",
      "0.10252639574464928 0.9588644464734528\n",
      "0.10246536479954324 0.9588893825583885\n",
      "0.10237188566902279 0.9589273147964399\n",
      "0.10231718950886014 0.9589407914880206\n",
      "0.10231233312974594 0.9589344998195312\n",
      "0.1023487641258803 0.9589282628689771\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-6f0b75fe735c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# считаем лосс\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# считаем accuract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_loss = []\n",
    "epoch_acc = []\n",
    "\n",
    "# включаем training mode\n",
    "model.train()  \n",
    "\n",
    "for i, batch in enumerate(iterator):\n",
    "\n",
    "    #обнуляем градиенты - не так важно сразу понимать\n",
    "    optimizer.zero_grad()   \n",
    "\n",
    "\n",
    "    texts, labels = batch[0], batch[1]   \n",
    "\n",
    "    #пропускаем тексты через модель (вызываем forward) \n",
    "    predictions = model(texts).squeeze()  \n",
    "\n",
    "    # считаем лосс\n",
    "    loss = criterion(predictions, torch.Tensor(labels).to(device))        \n",
    "\n",
    "    # считаем accuract\n",
    "    acc = accuracy(predictions, torch.Tensor(labels).to(device))   \n",
    "\n",
    "    # делаем backprop\n",
    "    loss.backward()       \n",
    "\n",
    "    # обновляем веса\n",
    "    optimizer.step()      \n",
    "\n",
    "    #loss and accuracy\n",
    "    epoch_loss.append(loss.item())  \n",
    "    epoch_acc.append(acc.item())\n",
    "    \n",
    "    \n",
    "    if not ((i)+1)%100:\n",
    "        print(np.mean(epoch_loss), np.mean(epoch_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# иногда будут возникать ошибки с кудой, можно попробовать запустить такой код\n",
    "# или попробовать батч сайз поменьше\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = []\n",
    "test_acc = []\n",
    "\n",
    "# выключаем training mode\n",
    "model.eval()  \n",
    "iterator_test = generate_batches_test(test, 20)\n",
    "for i, batch in enumerate(iterator_test):\n",
    "\n",
    "    texts, labels = batch[0], batch[1]   \n",
    "\n",
    "    # пропускаем тексты через модель (вызываем forward) \n",
    "    predictions = model(texts).squeeze()  \n",
    "\n",
    "    # считаем лосс\n",
    "    loss = criterion(predictions, torch.Tensor(labels).to(device))        \n",
    "\n",
    "    # считаем accuract\n",
    "    acc = accuracy(predictions, torch.Tensor(labels).to(device))   \n",
    "\n",
    "    # ничего не обновляем   \n",
    "    \n",
    "    test_loss.append(loss.item())  \n",
    "    test_acc.append(acc.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09276314006000899 0.9620826965451789\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(test_loss), np.mean(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type CLF. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'en_bert_finetuned_quora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
